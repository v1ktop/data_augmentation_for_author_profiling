{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load datasets\n",
    "2. Number of samples\n",
    "3. Number of words per sample\n",
    "4. Numbers of words by tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocesing.load_datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=Dataset()\n",
    "remove_end=False\n",
    "by_post=True\n",
    "docs_test, y_test=dataset.pan_19(folder_name=\"prep_files\", truth_name=\"test_truth_genre.txt\", \n",
    "                                 remove_end=remove_end, key=\"pan19_en\",  partition=\"test\", by_post=by_post)\n",
    "\n",
    "docs_train, y_train, = dataset.pan_19(folder_name=\"prep_files\",truth_name=\"training_truth_genre.txt\",\n",
    "                                           remove_end=remove_end, key=\"pan19_en\", partition=\"train\", by_post=by_post)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size 620\n"
     ]
    }
   ],
   "source": [
    "print(\"Test size\", len(docs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing size 1440\n"
     ]
    }
   ],
   "source": [
    "print(\"Traing size\", len(docs_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of words by sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_words=np.zeros(len(docs_train))\n",
    "len_tokens=np.zeros(len(docs_train))\n",
    "words_posts=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "for doc in docs_train:\n",
    "    tokens=doc.split(' ')\n",
    "    len_tokens[c]=len(tokens)\n",
    "    len_words[c]=len([w for w in tokens if w.isalpha()])\n",
    "    \n",
    "    #Count the number of posts and tokens by post\n",
    "    posts=doc.split('end_')\n",
    "    if len(posts) >1:\n",
    "        for post in posts:\n",
    "            words=post.split(' ')\n",
    "            words_posts.append(len([w for w in words]))\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics(vector):\n",
    "    values={}\n",
    "    values['min']=np.amin(vector)\n",
    "    values['max']=np.amax(vector)\n",
    "    values['range']=np.ptp(vector)\n",
    "    values['mean']=np.mean(vector)\n",
    "    values['median']=np.median(vector)\n",
    "    values['std']=np.std(vector)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': 616.0,\n",
       " 'max': 3305.0,\n",
       " 'range': 2689.0,\n",
       " 'mean': 1637.1763888888888,\n",
       " 'median': 1593.0,\n",
       " 'std': 401.26851393530586}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_w=compute_statistics(len_words)\n",
    "st_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_post=len(words_posts)\n",
    "num_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': 2.0,\n",
       " 'max': 344.0,\n",
       " 'range': 342.0,\n",
       " 'mean': 19.99834,\n",
       " 'median': 19.0,\n",
       " 'std': 10.55101}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_p=compute_statistics(np.asarray(words_posts, dtype=np.float32))\n",
    "st_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7578.9473684210525"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_post/19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
