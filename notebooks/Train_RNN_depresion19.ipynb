{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Train_RNN_depresion19.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"CCWrnxI7CYd1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1597362232514,"user_tz":300,"elapsed":1154,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}},"outputId":"7ceb4a30-fc18-41aa-dc48-577b40a9c01c"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uobCkaa6wQtc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":237},"executionInfo":{"status":"ok","timestamp":1597362271093,"user_tz":300,"elapsed":39703,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}},"outputId":"fd7e4268-9f1f-4dd4-8549-683ceeec399e"},"source":["!pip install git+https://github.com/facebookresearch/fastText"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/facebookresearch/fastText\n","  Cloning https://github.com/facebookresearch/fastText to /tmp/pip-req-build-ufoh3347\n","  Running command git clone -q https://github.com/facebookresearch/fastText /tmp/pip-req-build-ufoh3347\n","Requirement already satisfied (use --upgrade to upgrade): fasttext==0.9.2 from git+https://github.com/facebookresearch/fastText in /usr/local/lib/python3.6/dist-packages\n","Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (2.5.0)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (49.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (1.18.5)\n","Building wheels for collected packages: fasttext\n","  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3009145 sha256=ab1f4bc05ed40491e3fbf2d2999f2973b3c5b683abee58507becd2b6e63e31af\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-kb2cv_k1/wheels/72/f6/b9/3a859d37e24c73635e6c6af085ad99829e8b2ab1bd965b15a9\n","Successfully built fasttext\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PiCqYu1RfYM_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597362271095,"user_tz":300,"elapsed":39685,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}}},"source":["#%tensorflow_version 2.x"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"U29r_cAB_6mq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597362271378,"user_tz":300,"elapsed":39950,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}},"outputId":"70cef559-1009-4bd0-a636-a775acccc3f0"},"source":["import tensorflow as tf\n","tf.__version__"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.3.0'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"zMp2X8GwCmS_","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"-fOQ82fCDBYh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1597362274401,"user_tz":300,"elapsed":42949,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}},"outputId":"13c983a1-6845-4b14-ea16-1c026e181cf2"},"source":["!ls /content/drive/My\\ Drive/Code/data_aumentation_for_author_profiling"],"execution_count":5,"outputs":[{"output_type":"stream","text":["figures  notebooks  predictions  word_level_da\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qsyc7o4dS5sP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":100},"executionInfo":{"status":"ok","timestamp":1597362277291,"user_tz":300,"elapsed":45820,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}},"outputId":"45683ae4-c1be-4764-fb87-e6a2309dd9a0"},"source":["!ls /content/drive/My\\ Drive/Data/depresion/2019/train"],"execution_count":6,"outputs":[{"output_type":"stream","text":["augmented\t\t   original_prep\n","class_distpng\t\t   original_prep_ground_truth.txt\n","golden_truth_filtered.txt  prep_chunks\n","golden_truth.txt\t   prep_chunks_filtered_neg_only\n","ground_truth.txt\t   train_golden_truth_joined.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bmuTm9OEFCsv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597362277293,"user_tz":300,"elapsed":45800,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}}},"source":["import sys\n","sys.path.append('/content/drive/My Drive/Code/data_aumentation_for_author_profiling/')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"YxRF12KPKA6b","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597362277597,"user_tz":300,"elapsed":46089,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}}},"source":["\n","from datetime import datetime\n","from word_level_da import utils\n","from word_level_da.preprocessing.load_data import Dataset"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"T4xX-slcKuFg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597362277598,"user_tz":300,"elapsed":46075,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}}},"source":["  epochs= 20      \n","  layers=1\n","  nodes=256\n","  dim=300\n","  label_pos=1\n","  len_doc=64\n","  key=\"depresion19_drive\"\n","  LOAD_EMB=False\n","  fast_file='cc.en.300.bin'\n","  "],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"pW8W-AVwmdx4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597362277599,"user_tz":300,"elapsed":46061,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}}},"source":[""],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"tX2YwljSv7iK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597362277600,"user_tz":300,"elapsed":46029,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}}},"source":[""],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"NnVaOPXRBW1e","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597362277602,"user_tz":300,"elapsed":46013,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}}},"source":["if LOAD_EMB:\n","  import fasttext.util\n","  fasttext.util.download_model('en', if_exists='ignore')  # English\n","  ft = fasttext.load_model('cc.en.300.bin')"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"7E5ANiOroZt2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597362277604,"user_tz":300,"elapsed":45989,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}}},"source":["from word_level_da.classifier.train_sequence_model import seq_model\n","import numpy as np"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"e1svGgniNVL3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597362277605,"user_tz":300,"elapsed":45973,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}}},"source":[""],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"KouOxkiDNK5H","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597362277606,"user_tz":300,"elapsed":45957,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}}},"source":["data = Dataset(key=key, doc_len=len_doc, min_len=int(len_doc / 2), chunking=True, remove_end=True)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bbd8UHnOBiFW","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597362279559,"user_tz":300,"elapsed":47887,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}}},"source":["training, test=data.get_train_test(return_ids=True)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"sigbuhl1g0Pi","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597362279562,"user_tz":300,"elapsed":47871,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}}},"source":[""],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"IeQSmcx2bTAh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597362279564,"user_tz":300,"elapsed":47851,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}}},"source":["bi_gru=seq_model(weights_path=\"/content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/\", \n","                 static=False, load_all_vectors=LOAD_EMB,\n","                 ids_labels=dict.fromkeys(test[2]).keys(), original_labels=test[3][0])"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"m2Zu4xpo-t0A","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597362279566,"user_tz":300,"elapsed":47831,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}}},"source":[""],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"96oTBzNrx4Lf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597362279568,"user_tz":300,"elapsed":47816,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}}},"source":["n_docs=[i for i in range(1,11)]\n","ratio=0\n","augmentation_method=\"Thesaurus\"\n","model=\"rnn-fixed\"\n","umbral=0.5\n","score_m=\"avg\"\n","q=75"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"gCl8r9AiU1fP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597362279569,"user_tz":300,"elapsed":47799,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}}},"source":["fold=0\n","n=0\n","#ratio=0\n","r=0.2"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"tsvUcRlx4-pq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597362279570,"user_tz":300,"elapsed":47788,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}}},"source":["scores=[]\n","AUGMENTED=True"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"Az1KbDgyNhhG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":100},"executionInfo":{"status":"ok","timestamp":1597362282725,"user_tz":300,"elapsed":50924,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}},"outputId":"55599893-f49a-4d19-bcf2-d2506ff1cc7c"},"source":["!ls \"/content/drive/My Drive/Code/data_aumentation_for_author_profiling/word_level_da/obj/\""],"execution_count":18,"outputs":[{"output_type":"stream","text":["depresion19_local.pkl\t\t\t    r0_depresion19_local.pkl\n","pos_depresion19_local.pkl\t\t    r1_depresion19_local.pkl\n","predictions_depresion18_localrnn-fixed.csv  WE_depresion18.pkl\n","predictions_depresion19_localcnn.csv\t    WE_depresion19.pkl\n","predictions_depresion19_localrnn-fixed.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iNSzh7AyHAKH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597369304810,"user_tz":300,"elapsed":7072986,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}},"outputId":"fa3893d3-d298-48ca-c665-fd7daf2493a6"},"source":["for n in n_docs:\n","      prefix = augmentation_method + str(n)\n","      folder = augmentation_method + \"/\" + prefix\n","      truth_file = augmentation_method + \"/\" + prefix + \".txt\"\n","\n","      \n","      if AUGMENTED:\n","        docs, l_docs, ids, useless_data = data.get_dataset(folder_name=folder, truth_name=truth_file,\n","                                                               partition=\"augmented\")\n","                \n","        new_training=np.append(training[0],docs)\n","        new_labels=np.append( training[1], l_docs)\n","      else:\n","        new_training=training[0]\n","        new_labels=training[1]\n","\n","      info=bi_gru.buil_model(((new_training, new_labels), (test[0], test[1])), layers=1, nodes=nodes, embedding_dim=dim, dropout_rate=r, TOP_K=150000, \n","                                pretrained=True, embedding_trainable=False, bidirectional=True, \n","                          seq_len=len_doc, emb_file=fast_file, class_imbanlance=True, algo=model,\n","                          kernel_size=None, vocab_dir=\"/content/drive/My Drive/Code/data_aumentation_for_author_profiling/word_level_da/obj\",\n","                           key=key.split(\"_\")[0])\n","      info[2]=umbral\n","      for i in range(3):\n","        score=bi_gru.train_model(1e-3, epochs=epochs, patience=3, batch_size=1024, load_weights=False, \n","                                                weights_name=key.split(\"_\")[0]+prefix+model+str(i)+\".h5\",\n","                                  ad_data=(test[3]), monitor_measure=\"val_loss\", validation=True,\n","                                 umbral=umbral,  score_method=score_m, q=q)\n","        \n","        final_info=[augmentation_method,n,i ]\n","        final_info+=info+list(score)\n","        scores.append(final_info)\n","        print(final_info)\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Number of new embeddings:  0\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 64, 300)           35740800  \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, 512)               1140736   \n","_________________________________________________________________\n","dropout (Dropout)            (None, 512)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               131328    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 37,013,121\n","Trainable params: 1,272,321\n","Non-trainable params: 35,740,800\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.74187, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus1rnn-fixed0.h5\n","135/135 - 31s - loss: 0.7390 - acc: 0.4969 - val_loss: 0.7419 - val_acc: 0.4702\n","Epoch 2/20\n","\n","Epoch 00002: val_loss improved from 0.74187 to 0.71093, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus1rnn-fixed0.h5\n","135/135 - 30s - loss: 0.6042 - acc: 0.7313 - val_loss: 0.7109 - val_acc: 0.5190\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.71093\n","135/135 - 29s - loss: 0.5756 - acc: 0.7434 - val_loss: 0.7803 - val_acc: 0.4453\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.71093\n","135/135 - 29s - loss: 0.5632 - acc: 0.7562 - val_loss: 1.2034 - val_acc: 0.3767\n","Epoch 5/20\n","\n","Epoch 00005: val_loss did not improve from 0.71093\n","135/135 - 29s - loss: 0.5524 - acc: 0.7533 - val_loss: 0.8781 - val_acc: 0.4235\n","['Thesaurus', 1, 0, 119135, 150000, 0.5, 64, {0: 0.5457825675750856, 1: 5.960593698463675}, 2.3907047003877886, 0.6285714285714286, 0.8863636363636364, 0.65, 0.75, 0.5523725152015686, 0.7562252283096313, 0.7109277248382568, 0.5190061330795288, 0.7390488386154175, 0.6041590571403503, 0.5756254196166992, 0.5632308721542358, 0.5523725152015686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.496934711933136, 0.731309711933136, 0.7434179782867432, 0.7562252283096313, 0.7533201575279236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7418658137321472, 0.7109277248382568, 0.7803154587745667, 1.2034186124801636, 0.8780515193939209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4701635241508484, 0.5190061330795288, 0.44531747698783875, 0.37668293714523315, 0.42348694801330566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 64, 300)           35740800  \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, 512)               1140736   \n","_________________________________________________________________\n","dropout (Dropout)            (None, 512)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               131328    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 37,013,121\n","Trainable params: 1,272,321\n","Non-trainable params: 35,740,800\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.85073, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus1rnn-fixed1.h5\n","135/135 - 31s - loss: 0.7656 - acc: 0.4761 - val_loss: 0.8507 - val_acc: 0.3813\n","Epoch 2/20\n","\n","Epoch 00002: val_loss improved from 0.85073 to 0.69918, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus1rnn-fixed1.h5\n","135/135 - 30s - loss: 0.6039 - acc: 0.7316 - val_loss: 0.6992 - val_acc: 0.5085\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.69918\n","135/135 - 29s - loss: 0.5865 - acc: 0.7551 - val_loss: 1.0193 - val_acc: 0.3049\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.69918\n","135/135 - 29s - loss: 0.5758 - acc: 0.7506 - val_loss: 1.0306 - val_acc: 0.3236\n","Epoch 5/20\n","\n","Epoch 00005: val_loss did not improve from 0.69918\n","135/135 - 29s - loss: 0.5641 - acc: 0.7495 - val_loss: 0.8525 - val_acc: 0.4495\n","['Thesaurus', 1, 1, 119135, 150000, 0.5, 64, {0: 0.5457825675750856, 1: 5.960593698463675}, 2.3907047003877886, 0.6428571428571429, 0.8888888888888888, 0.6666666666666666, 0.761904761904762, 0.5640854835510254, 0.7550748586654663, 0.6991814374923706, 0.5085155963897705, 0.7655813694000244, 0.6038633584976196, 0.5864703059196472, 0.5758212804794312, 0.5640854835510254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4760819673538208, 0.7316228151321411, 0.7550748586654663, 0.7505679130554199, 0.7495267391204834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8507258296012878, 0.6991814374923706, 1.0192536115646362, 1.0306447744369507, 0.8524749279022217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3812699019908905, 0.5085155963897705, 0.304905503988266, 0.3236355781555176, 0.44947972893714905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 64, 300)           35740800  \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, 512)               1140736   \n","_________________________________________________________________\n","dropout (Dropout)            (None, 512)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               131328    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 37,013,121\n","Trainable params: 1,272,321\n","Non-trainable params: 35,740,800\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.74091, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus1rnn-fixed2.h5\n","135/135 - 32s - loss: 0.7792 - acc: 0.4591 - val_loss: 0.7409 - val_acc: 0.4652\n","Epoch 2/20\n","\n","Epoch 00002: val_loss did not improve from 0.74091\n","135/135 - 29s - loss: 0.6223 - acc: 0.6904 - val_loss: 0.7500 - val_acc: 0.4483\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.74091\n","135/135 - 29s - loss: 0.5873 - acc: 0.7292 - val_loss: 0.8229 - val_acc: 0.4288\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.74091\n","135/135 - 29s - loss: 0.5694 - acc: 0.7408 - val_loss: 0.8190 - val_acc: 0.4315\n","['Thesaurus', 1, 2, 119135, 150000, 0.5, 64, {0: 0.5457825675750856, 1: 5.960593698463675}, 2.3907047003877886, 0.5285714285714286, 0.9090909090909091, 0.5, 0.6451612903225806, 0.5694287419319153, 0.7408114075660706, 0.7409059405326843, 0.465151846408844, 0.7792268991470337, 0.6222994327545166, 0.5872784852981567, 0.5694287419319153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45912453532218933, 0.6903978586196899, 0.72916179895401, 0.7408114075660706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7409059405326843, 0.7500208020210266, 0.8228934407234192, 0.8190013766288757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.465151846408844, 0.44829049706459045, 0.4287959337234497, 0.43151411414146423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Number of new embeddings:  0\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 64, 300)           35813700  \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 37,086,021\n","Trainable params: 1,272,321\n","Non-trainable params: 35,813,700\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.85140, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus2rnn-fixed0.h5\n","140/140 - 33s - loss: 0.7550 - acc: 0.4737 - val_loss: 0.8514 - val_acc: 0.3524\n","Epoch 2/20\n","\n","Epoch 00002: val_loss improved from 0.85140 to 0.81355, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus2rnn-fixed0.h5\n","140/140 - 31s - loss: 0.5962 - acc: 0.7422 - val_loss: 0.8135 - val_acc: 0.3964\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.81355\n","140/140 - 30s - loss: 0.5786 - acc: 0.7598 - val_loss: 0.8790 - val_acc: 0.3264\n","Epoch 4/20\n","\n","Epoch 00004: val_loss improved from 0.81355 to 0.73392, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus2rnn-fixed0.h5\n","140/140 - 31s - loss: 0.5603 - acc: 0.7509 - val_loss: 0.7339 - val_acc: 0.5381\n","Epoch 5/20\n","\n","Epoch 00005: val_loss did not improve from 0.73392\n","140/140 - 30s - loss: 0.5491 - acc: 0.7467 - val_loss: 0.9765 - val_acc: 0.4249\n","Epoch 6/20\n","\n","Epoch 00006: val_loss did not improve from 0.73392\n","140/140 - 30s - loss: 0.5371 - acc: 0.7547 - val_loss: 0.8161 - val_acc: 0.4664\n","Epoch 7/20\n","\n","Epoch 00007: val_loss did not improve from 0.73392\n","140/140 - 30s - loss: 0.5303 - acc: 0.7588 - val_loss: 0.9275 - val_acc: 0.3801\n","['Thesaurus', 2, 0, 119378, 150000, 0.5, 64, {0: 0.5687950533686209, 1: 4.1339822088724585}, 1.983476254779634, 0.5571428571428572, 0.9142857142857143, 0.5333333333333333, 0.6736842105263158, 0.5303364992141724, 0.7598351240158081, 0.7339245080947876, 0.5380760431289673, 0.7549962401390076, 0.5962072610855103, 0.5785683393478394, 0.5603291392326355, 0.5490819215774536, 0.5370880961418152, 0.5303364992141724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4737066328525543, 0.742194414138794, 0.7598351240158081, 0.7509344220161438, 0.7467285990715027, 0.754665195941925, 0.7588081359863281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8514019250869751, 0.8135461807250977, 0.8790398240089417, 0.7339245080947876, 0.9765340685844421, 0.8160926699638367, 0.9275255799293518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35238903760910034, 0.396389901638031, 0.3264387249946594, 0.5380760431289673, 0.42493098974227905, 0.46638351678848267, 0.38012316823005676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 64, 300)           35813700  \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 37,086,021\n","Trainable params: 1,272,321\n","Non-trainable params: 35,813,700\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.74606, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus2rnn-fixed1.h5\n","140/140 - 33s - loss: 0.7555 - acc: 0.4791 - val_loss: 0.7461 - val_acc: 0.4694\n","Epoch 2/20\n","\n","Epoch 00002: val_loss did not improve from 0.74606\n","140/140 - 30s - loss: 0.5959 - acc: 0.7442 - val_loss: 0.8503 - val_acc: 0.3607\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.74606\n","140/140 - 30s - loss: 0.5776 - acc: 0.7670 - val_loss: 0.9206 - val_acc: 0.3593\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.74606\n","140/140 - 30s - loss: 0.5652 - acc: 0.7540 - val_loss: 0.8475 - val_acc: 0.4127\n","['Thesaurus', 2, 1, 119378, 150000, 0.5, 64, {0: 0.5687950533686209, 1: 4.1339822088724585}, 1.983476254779634, 0.5857142857142857, 0.8974358974358975, 0.5833333333333334, 0.7070707070707071, 0.5652428865432739, 0.7669682502746582, 0.746063232421875, 0.4694415032863617, 0.7554509043693542, 0.5958590507507324, 0.5775996446609497, 0.5652428865432739, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4790722131729126, 0.7442344427108765, 0.7669682502746582, 0.7540364265441895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.746063232421875, 0.8503357768058777, 0.9206110239028931, 0.8475024700164795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4694415032863617, 0.3606710433959961, 0.35931196808815, 0.4126990735530853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 64, 300)           35813700  \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 37,086,021\n","Trainable params: 1,272,321\n","Non-trainable params: 35,813,700\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.79177, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus2rnn-fixed2.h5\n","140/140 - 32s - loss: 0.7174 - acc: 0.5090 - val_loss: 0.7918 - val_acc: 0.3924\n","Epoch 2/20\n","\n","Epoch 00002: val_loss improved from 0.79177 to 0.77437, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus2rnn-fixed2.h5\n","140/140 - 31s - loss: 0.6028 - acc: 0.7195 - val_loss: 0.7744 - val_acc: 0.4509\n","Epoch 3/20\n","\n","Epoch 00003: val_loss improved from 0.77437 to 0.73257, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus2rnn-fixed2.h5\n","140/140 - 31s - loss: 0.5769 - acc: 0.7268 - val_loss: 0.7326 - val_acc: 0.5080\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.73257\n","140/140 - 30s - loss: 0.5623 - acc: 0.7362 - val_loss: 0.9042 - val_acc: 0.3523\n","Epoch 5/20\n","\n","Epoch 00005: val_loss did not improve from 0.73257\n","140/140 - 30s - loss: 0.5457 - acc: 0.7445 - val_loss: 0.9394 - val_acc: 0.4214\n","Epoch 6/20\n","\n","Epoch 00006: val_loss did not improve from 0.73257\n","140/140 - 30s - loss: 0.5328 - acc: 0.7523 - val_loss: 0.9138 - val_acc: 0.4212\n","['Thesaurus', 2, 2, 119378, 150000, 0.5, 64, {0: 0.5687950533686209, 1: 4.1339822088724585}, 1.983476254779634, 0.5285714285714286, 0.8648648648648649, 0.5333333333333333, 0.6597938144329898, 0.532768189907074, 0.7522897720336914, 0.7325745224952698, 0.5079634785652161, 0.7173711061477661, 0.6028207540512085, 0.5768615007400513, 0.562320351600647, 0.5456681251525879, 0.532768189907074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.508994996547699, 0.7194886207580566, 0.7268243432044983, 0.7361721396446228, 0.744458019733429, 0.7522897720336914, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7917695045471191, 0.774373471736908, 0.7325745224952698, 0.9041884541511536, 0.9394355416297913, 0.9138451814651489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39239752292633057, 0.45092377066612244, 0.5079634785652161, 0.3523465692996979, 0.421448290348053, 0.42115098237991333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Number of new embeddings:  0\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (None, 64, 300)           35883300  \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 37,155,621\n","Trainable params: 1,272,321\n","Non-trainable params: 35,883,300\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.72318, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus3rnn-fixed0.h5\n","146/146 - 34s - loss: 0.7149 - acc: 0.5198 - val_loss: 0.7232 - val_acc: 0.4687\n","Epoch 2/20\n","\n","Epoch 00002: val_loss did not improve from 0.72318\n","146/146 - 31s - loss: 0.5902 - acc: 0.7494 - val_loss: 0.7943 - val_acc: 0.4003\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.72318\n","146/146 - 31s - loss: 0.5662 - acc: 0.7501 - val_loss: 0.9027 - val_acc: 0.3925\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.72318\n","146/146 - 31s - loss: 0.5501 - acc: 0.7497 - val_loss: 0.9272 - val_acc: 0.4645\n","['Thesaurus', 3, 0, 119610, 150000, 0.5, 64, {0: 0.5918115129984184, 1: 3.2229700484764545}, 1.6948703947332893, 0.5142857142857142, 0.8823529411764706, 0.5, 0.6382978723404256, 0.5500746369361877, 0.7501124739646912, 0.7231831550598145, 0.468719482421875, 0.7148877382278442, 0.5902256369590759, 0.5662277340888977, 0.5500746369361877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5198318362236023, 0.7494410276412964, 0.7501124739646912, 0.7496894598007202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7231831550598145, 0.7942537069320679, 0.9026620984077454, 0.9271824955940247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.468719482421875, 0.4002973139286041, 0.3924824893474579, 0.46451476216316223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (None, 64, 300)           35883300  \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 37,155,621\n","Trainable params: 1,272,321\n","Non-trainable params: 35,883,300\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.79093, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus3rnn-fixed1.h5\n","146/146 - 33s - loss: 0.6583 - acc: 0.6001 - val_loss: 0.7909 - val_acc: 0.4114\n","Epoch 2/20\n","\n","Epoch 00002: val_loss did not improve from 0.79093\n","146/146 - 31s - loss: 0.5857 - acc: 0.7318 - val_loss: 0.9422 - val_acc: 0.3573\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.79093\n","146/146 - 31s - loss: 0.5591 - acc: 0.7467 - val_loss: 0.8735 - val_acc: 0.4421\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.79093\n","146/146 - 31s - loss: 0.5456 - acc: 0.7474 - val_loss: 0.8663 - val_acc: 0.4311\n","['Thesaurus', 3, 1, 119610, 150000, 0.5, 64, {0: 0.5918115129984184, 1: 3.2229700484764545}, 1.6948703947332893, 0.4857142857142857, 0.9, 0.45, 0.6, 0.545594334602356, 0.7473796010017395, 0.7909324169158936, 0.4421320855617523, 0.65833580493927, 0.5857086777687073, 0.5590552687644958, 0.545594334602356, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6001463532447815, 0.731774628162384, 0.7466946840286255, 0.7473796010017395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7909324169158936, 0.9422025680541992, 0.8735074400901794, 0.8662606477737427, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4114249348640442, 0.3573157787322998, 0.4421320855617523, 0.43113186955451965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (None, 64, 300)           35883300  \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 37,155,621\n","Trainable params: 1,272,321\n","Non-trainable params: 35,883,300\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.75591, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus3rnn-fixed2.h5\n","146/146 - 34s - loss: 0.7302 - acc: 0.5037 - val_loss: 0.7559 - val_acc: 0.4268\n","Epoch 2/20\n","\n","Epoch 00002: val_loss did not improve from 0.75591\n","146/146 - 32s - loss: 0.5921 - acc: 0.7347 - val_loss: 0.8450 - val_acc: 0.4066\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.75591\n","146/146 - 31s - loss: 0.5675 - acc: 0.7339 - val_loss: 0.7688 - val_acc: 0.4517\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.75591\n","146/146 - 31s - loss: 0.5516 - acc: 0.7416 - val_loss: 0.7895 - val_acc: 0.4820\n","['Thesaurus', 3, 2, 119610, 150000, 0.5, 64, {0: 0.5918115129984184, 1: 3.2229700484764545}, 1.6948703947332893, 0.4, 0.95, 0.31666666666666665, 0.4749999999999999, 0.5515599250793457, 0.7415915131568909, 0.7559108138084412, 0.48201316595077515, 0.7302101850509644, 0.5920588374137878, 0.5674872994422913, 0.5515599250793457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5037165880203247, 0.7347425222396851, 0.7338628768920898, 0.7415915131568909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7559108138084412, 0.8449685573577881, 0.7688276171684265, 0.789486289024353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.426757276058197, 0.40658313035964966, 0.4516882598400116, 0.48201316595077515, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Number of new embeddings:  0\n","Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_3 (Embedding)      (None, 64, 300)           35922600  \n","_________________________________________________________________\n","bidirectional_3 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 37,194,921\n","Trainable params: 1,272,321\n","Non-trainable params: 35,922,600\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.89641, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus4rnn-fixed0.h5\n","152/152 - 35s - loss: 0.6965 - acc: 0.5477 - val_loss: 0.8964 - val_acc: 0.3517\n","Epoch 2/20\n","\n","Epoch 00002: val_loss improved from 0.89641 to 0.84014, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus4rnn-fixed0.h5\n","152/152 - 34s - loss: 0.5748 - acc: 0.7479 - val_loss: 0.8401 - val_acc: 0.4228\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.84014\n","152/152 - 33s - loss: 0.5507 - acc: 0.7434 - val_loss: 0.8694 - val_acc: 0.4272\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.84014\n","152/152 - 32s - loss: 0.5357 - acc: 0.7529 - val_loss: 0.9410 - val_acc: 0.4090\n","Epoch 5/20\n","\n","Epoch 00005: val_loss did not improve from 0.84014\n","152/152 - 33s - loss: 0.5202 - acc: 0.7676 - val_loss: 0.8882 - val_acc: 0.4841\n","['Thesaurus', 4, 0, 119741, 150000, 0.5, 64, {0: 0.6148359203007399, 1: 2.6770191708768776}, 1.4711037688722857, 0.34285714285714286, 0.9375, 0.25, 0.39473684210526316, 0.5201846361160278, 0.7676333785057068, 0.8401395678520203, 0.4840942919254303, 0.6965358853340149, 0.5747877955436707, 0.550711452960968, 0.535679817199707, 0.5201846361160278, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5477020144462585, 0.7478945851325989, 0.7434478998184204, 0.7528519034385681, 0.7676333785057068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8964100480079651, 0.8401395678520203, 0.8693966865539551, 0.9410485029220581, 0.8882347941398621, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35166701674461365, 0.42276492714881897, 0.42722445726394653, 0.40896156430244446, 0.4840942919254303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_3 (Embedding)      (None, 64, 300)           35922600  \n","_________________________________________________________________\n","bidirectional_3 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 37,194,921\n","Trainable params: 1,272,321\n","Non-trainable params: 35,922,600\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.72861, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus4rnn-fixed1.h5\n","152/152 - 35s - loss: 0.6579 - acc: 0.6067 - val_loss: 0.7286 - val_acc: 0.4724\n","Epoch 2/20\n","\n","Epoch 00002: val_loss did not improve from 0.72861\n","152/152 - 33s - loss: 0.5813 - acc: 0.7285 - val_loss: 0.8254 - val_acc: 0.4308\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.72861\n","152/152 - 32s - loss: 0.5576 - acc: 0.7444 - val_loss: 0.8039 - val_acc: 0.4682\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.72861\n","152/152 - 32s - loss: 0.5477 - acc: 0.7502 - val_loss: 0.9553 - val_acc: 0.3901\n","['Thesaurus', 4, 1, 119741, 150000, 0.5, 64, {0: 0.6148359203007399, 1: 2.6770191708768776}, 1.4711037688722857, 0.5714285714285714, 0.8947368421052632, 0.5666666666666667, 0.6938775510204083, 0.5477373600006104, 0.7501567602157593, 0.7286137342453003, 0.4724145233631134, 0.6579127311706543, 0.5812795162200928, 0.5575545430183411, 0.5477373600006104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6066726446151733, 0.7285242676734924, 0.7444367408752441, 0.7501567602157593, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7286137342453003, 0.8254004716873169, 0.8039093017578125, 0.9553460478782654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4724145233631134, 0.43079209327697754, 0.46816733479499817, 0.3901040554046631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_3 (Embedding)      (None, 64, 300)           35922600  \n","_________________________________________________________________\n","bidirectional_3 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 37,194,921\n","Trainable params: 1,272,321\n","Non-trainable params: 35,922,600\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.69069, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus4rnn-fixed2.h5\n","152/152 - 34s - loss: 0.6719 - acc: 0.5693 - val_loss: 0.6907 - val_acc: 0.5549\n","Epoch 2/20\n","\n","Epoch 00002: val_loss did not improve from 0.69069\n","152/152 - 33s - loss: 0.5787 - acc: 0.7209 - val_loss: 1.0987 - val_acc: 0.3222\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.69069\n","152/152 - 32s - loss: 0.5576 - acc: 0.7431 - val_loss: 0.7320 - val_acc: 0.5273\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.69069\n","152/152 - 33s - loss: 0.5462 - acc: 0.7471 - val_loss: 1.1520 - val_acc: 0.3774\n","['Thesaurus', 4, 2, 119741, 150000, 0.5, 64, {0: 0.6148359203007399, 1: 2.6770191708768776}, 1.4711037688722857, 0.7142857142857143, 0.8448275862068966, 0.8166666666666667, 0.8305084745762712, 0.5461557507514954, 0.7470996379852295, 0.6906864047050476, 0.5549373626708984, 0.6719282865524292, 0.578691840171814, 0.5575836300849915, 0.5461557507514954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5693409442901611, 0.7208782434463501, 0.7431376576423645, 0.7470996379852295, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6906864047050476, 1.0986742973327637, 0.731951117515564, 1.1519688367843628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5549373626708984, 0.32223403453826904, 0.5272881984710693, 0.3773624897003174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Number of new embeddings:  0\n","Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_4 (Embedding)      (None, 64, 300)           35977200  \n","_________________________________________________________________\n","bidirectional_4 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 37,249,521\n","Trainable params: 1,272,321\n","Non-trainable params: 35,977,200\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.70479, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus5rnn-fixed0.h5\n","157/157 - 36s - loss: 0.6384 - acc: 0.6328 - val_loss: 0.7048 - val_acc: 0.5198\n","Epoch 2/20\n","\n","Epoch 00002: val_loss did not improve from 0.70479\n","157/157 - 34s - loss: 0.5739 - acc: 0.7202 - val_loss: 0.7666 - val_acc: 0.4493\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.70479\n","157/157 - 34s - loss: 0.5511 - acc: 0.7380 - val_loss: 0.8052 - val_acc: 0.4804\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.70479\n","157/157 - 34s - loss: 0.5313 - acc: 0.7532 - val_loss: 0.8599 - val_acc: 0.4203\n","['Thesaurus', 5, 0, 119923, 150000, 0.5, 64, {0: 0.6378762229481096, 1: 2.313220544154946}, 1.2882517509106401, 0.6285714285714286, 0.8541666666666666, 0.6833333333333333, 0.7592592592592592, 0.5313342213630676, 0.7531507015228271, 0.7047932744026184, 0.5198131203651428, 0.6384124755859375, 0.5739018321037292, 0.5511488914489746, 0.5313342213630676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6328160762786865, 0.7201889157295227, 0.7379749417304993, 0.7531507015228271, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7047932744026184, 0.7665608525276184, 0.8051616549491882, 0.8598889708518982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5198131203651428, 0.4493098258972168, 0.48035675287246704, 0.42030155658721924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_4 (Embedding)      (None, 64, 300)           35977200  \n","_________________________________________________________________\n","bidirectional_4 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 37,249,521\n","Trainable params: 1,272,321\n","Non-trainable params: 35,977,200\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.70041, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus5rnn-fixed1.h5\n","157/157 - 36s - loss: 0.6218 - acc: 0.6606 - val_loss: 0.7004 - val_acc: 0.5544\n","Epoch 2/20\n","\n","Epoch 00002: val_loss did not improve from 0.70041\n","157/157 - 34s - loss: 0.5667 - acc: 0.7330 - val_loss: 0.8353 - val_acc: 0.4281\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.70041\n","157/157 - 34s - loss: 0.5454 - acc: 0.7467 - val_loss: 0.9121 - val_acc: 0.4415\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.70041\n","157/157 - 33s - loss: 0.5250 - acc: 0.7613 - val_loss: 0.9368 - val_acc: 0.4454\n","['Thesaurus', 5, 1, 119923, 150000, 0.5, 64, {0: 0.6378762229481096, 1: 2.313220544154946}, 1.2882517509106401, 0.6857142857142857, 0.8518518518518519, 0.7666666666666667, 0.8070175438596491, 0.5250306129455566, 0.7612868547439575, 0.7004138231277466, 0.554385244846344, 0.6217848062515259, 0.5666900873184204, 0.5454013347625732, 0.5250306129455566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6605635285377502, 0.7329599857330322, 0.746671736240387, 0.7612868547439575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7004138231277466, 0.8353338241577148, 0.9121208190917969, 0.9367709159851074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.554385244846344, 0.4281163811683655, 0.4414525330066681, 0.4453599452972412, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_4 (Embedding)      (None, 64, 300)           35977200  \n","_________________________________________________________________\n","bidirectional_4 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 37,249,521\n","Trainable params: 1,272,321\n","Non-trainable params: 35,977,200\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.91122, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus5rnn-fixed2.h5\n","157/157 - 36s - loss: 0.6499 - acc: 0.6120 - val_loss: 0.9112 - val_acc: 0.3307\n","Epoch 2/20\n","\n","Epoch 00002: val_loss improved from 0.91122 to 0.86759, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus5rnn-fixed2.h5\n","157/157 - 35s - loss: 0.5730 - acc: 0.7362 - val_loss: 0.8676 - val_acc: 0.4202\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.86759\n","157/157 - 34s - loss: 0.5466 - acc: 0.7491 - val_loss: 0.9010 - val_acc: 0.4343\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.86759\n","157/157 - 33s - loss: 0.5349 - acc: 0.7533 - val_loss: 0.8807 - val_acc: 0.4701\n","Epoch 5/20\n","\n","Epoch 00005: val_loss improved from 0.86759 to 0.85744, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus5rnn-fixed2.h5\n","157/157 - 35s - loss: 0.5188 - acc: 0.7647 - val_loss: 0.8574 - val_acc: 0.4417\n","Epoch 6/20\n","\n","Epoch 00006: val_loss did not improve from 0.85744\n","157/157 - 34s - loss: 0.4970 - acc: 0.7776 - val_loss: 0.8842 - val_acc: 0.4514\n","Epoch 7/20\n","\n","Epoch 00007: val_loss did not improve from 0.85744\n","157/157 - 34s - loss: 0.4705 - acc: 0.7922 - val_loss: 1.1861 - val_acc: 0.3963\n","Epoch 8/20\n","\n","Epoch 00008: val_loss did not improve from 0.85744\n","157/157 - 34s - loss: 0.4546 - acc: 0.8013 - val_loss: 0.9881 - val_acc: 0.4655\n","['Thesaurus', 5, 2, 119923, 150000, 0.5, 64, {0: 0.6378762229481096, 1: 2.313220544154946}, 1.2882517509106401, 0.34285714285714286, 0.8888888888888888, 0.26666666666666666, 0.41025641025641024, 0.45459139347076416, 0.8013194799423218, 0.8574418425559998, 0.4701210558414459, 0.6498685479164124, 0.5729726552963257, 0.5466099381446838, 0.5349365472793579, 0.5188189744949341, 0.49704620242118835, 0.47053995728492737, 0.45459139347076416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6120147705078125, 0.736211895942688, 0.7491137981414795, 0.7533376216888428, 0.7646883130073547, 0.7776151299476624, 0.7921554446220398, 0.8013194799423218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9112229943275452, 0.8675852417945862, 0.9010098576545715, 0.8807067275047302, 0.8574418425559998, 0.884204089641571, 1.1861263513565063, 0.9880574345588684, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3307283818721771, 0.42017412185668945, 0.4342747926712036, 0.4701210558414459, 0.44174984097480774, 0.4514334201812744, 0.3963049352169037, 0.4655340909957886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Number of new embeddings:  0\n","Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_5 (Embedding)      (None, 64, 300)           36002700  \n","_________________________________________________________________\n","bidirectional_5 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_10 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 37,275,021\n","Trainable params: 1,272,321\n","Non-trainable params: 36,002,700\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.79392, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus6rnn-fixed0.h5\n","163/163 - 38s - loss: 0.6276 - acc: 0.6459 - val_loss: 0.7939 - val_acc: 0.4229\n","Epoch 2/20\n","\n","Epoch 00002: val_loss did not improve from 0.79392\n","163/163 - 35s - loss: 0.5669 - acc: 0.7275 - val_loss: 1.0066 - val_acc: 0.3763\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.79392\n","163/163 - 35s - loss: 0.5423 - acc: 0.7468 - val_loss: 0.8031 - val_acc: 0.4873\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.79392\n","163/163 - 35s - loss: 0.5217 - acc: 0.7575 - val_loss: 0.9632 - val_acc: 0.4384\n","['Thesaurus', 6, 0, 120008, 150000, 0.5, 64, {0: 0.6608608918878106, 1: 2.0541378458498025}, 1.134068132464495, 0.45714285714285713, 0.9583333333333334, 0.38333333333333336, 0.5476190476190476, 0.521682858467102, 0.7575148940086365, 0.7939248085021973, 0.4872796833515167, 0.6276333928108215, 0.5668756365776062, 0.5422806143760681, 0.521682858467102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6459174156188965, 0.7274793386459351, 0.7467874884605408, 0.7575148940086365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7939248085021973, 1.0066081285476685, 0.8030921220779419, 0.9631925821304321, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42293480038642883, 0.3763006925582886, 0.4872796833515167, 0.43839457631111145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_5 (Embedding)      (None, 64, 300)           36002700  \n","_________________________________________________________________\n","bidirectional_5 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_10 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 37,275,021\n","Trainable params: 1,272,321\n","Non-trainable params: 36,002,700\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.91303, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus6rnn-fixed1.h5\n","163/163 - 37s - loss: 0.6258 - acc: 0.6567 - val_loss: 0.9130 - val_acc: 0.3590\n","Epoch 2/20\n","\n","Epoch 00002: val_loss did not improve from 0.91303\n","163/163 - 35s - loss: 0.5651 - acc: 0.7289 - val_loss: 0.9258 - val_acc: 0.3708\n","Epoch 3/20\n","\n","Epoch 00003: val_loss improved from 0.91303 to 0.89843, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus6rnn-fixed1.h5\n","163/163 - 36s - loss: 0.5472 - acc: 0.7388 - val_loss: 0.8984 - val_acc: 0.4136\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.89843\n","163/163 - 35s - loss: 0.5303 - acc: 0.7501 - val_loss: 1.0218 - val_acc: 0.3882\n","Epoch 5/20\n","\n","Epoch 00005: val_loss did not improve from 0.89843\n","163/163 - 35s - loss: 0.5077 - acc: 0.7630 - val_loss: 0.9088 - val_acc: 0.4574\n","Epoch 6/20\n","\n","Epoch 00006: val_loss did not improve from 0.89843\n","163/163 - 35s - loss: 0.4865 - acc: 0.7748 - val_loss: 0.9970 - val_acc: 0.4463\n","['Thesaurus', 6, 1, 120008, 150000, 0.5, 64, {0: 0.6608608918878106, 1: 2.0541378458498025}, 1.134068132464495, 0.22857142857142856, 1.0, 0.1, 0.18181818181818182, 0.48653310537338257, 0.7747605443000793, 0.8984289765357971, 0.4574219584465027, 0.6257790923118591, 0.5650733709335327, 0.5471505522727966, 0.5302534103393555, 0.50767982006073, 0.48653310537338257, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6567109227180481, 0.7288624048233032, 0.7388200759887695, 0.750112771987915, 0.7630228996276855, 0.7747605443000793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9130292534828186, 0.9258144497871399, 0.8984289765357971, 1.0218281745910645, 0.9087539911270142, 0.9969661831855774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3589721918106079, 0.37082183361053467, 0.41363346576690674, 0.3881928324699402, 0.4574219584465027, 0.4463368058204651, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_5 (Embedding)      (None, 64, 300)           36002700  \n","_________________________________________________________________\n","bidirectional_5 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_10 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 37,275,021\n","Trainable params: 1,272,321\n","Non-trainable params: 36,002,700\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.75380, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus6rnn-fixed2.h5\n","163/163 - 37s - loss: 0.6562 - acc: 0.6037 - val_loss: 0.7538 - val_acc: 0.4780\n","Epoch 2/20\n","\n","Epoch 00002: val_loss did not improve from 0.75380\n","163/163 - 35s - loss: 0.5709 - acc: 0.7330 - val_loss: 0.8537 - val_acc: 0.3907\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.75380\n","163/163 - 35s - loss: 0.5466 - acc: 0.7391 - val_loss: 0.8891 - val_acc: 0.4471\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.75380\n","163/163 - 35s - loss: 0.5295 - acc: 0.7499 - val_loss: 0.8717 - val_acc: 0.4483\n","['Thesaurus', 6, 2, 120008, 150000, 0.5, 64, {0: 0.6608608918878106, 1: 2.0541378458498025}, 1.134068132464495, 0.6, 0.9, 0.6, 0.7200000000000001, 0.5295224785804749, 0.7499383687973022, 0.7537975907325745, 0.47797834873199463, 0.6562120914459229, 0.5708787441253662, 0.5466402769088745, 0.5295224785804749, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6036511659622192, 0.7330474853515625, 0.7390906810760498, 0.7499383687973022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7537975907325745, 0.8537267446517944, 0.8890822529792786, 0.8717172145843506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47797834873199463, 0.3906986713409424, 0.44710129499435425, 0.4483329653739929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Number of new embeddings:  0\n","Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_6 (Embedding)      (None, 64, 300)           36052500  \n","_________________________________________________________________\n","bidirectional_6 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","dropout_13 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 37,324,821\n","Trainable params: 1,272,321\n","Non-trainable params: 36,052,500\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.85409, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus7rnn-fixed0.h5\n","169/169 - 38s - loss: 0.6201 - acc: 0.6636 - val_loss: 0.8541 - val_acc: 0.4505\n","Epoch 2/20\n","\n","Epoch 00002: val_loss improved from 0.85409 to 0.76175, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus7rnn-fixed0.h5\n","169/169 - 37s - loss: 0.5571 - acc: 0.7346 - val_loss: 0.7617 - val_acc: 0.5230\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.76175\n","169/169 - 37s - loss: 0.5324 - acc: 0.7443 - val_loss: 1.0550 - val_acc: 0.3951\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.76175\n","169/169 - 36s - loss: 0.5176 - acc: 0.7557 - val_loss: 0.8772 - val_acc: 0.4620\n","Epoch 5/20\n","\n","Epoch 00005: val_loss did not improve from 0.76175\n","169/169 - 36s - loss: 0.5036 - acc: 0.7638 - val_loss: 0.8657 - val_acc: 0.4830\n","['Thesaurus', 7, 0, 120174, 150000, 0.5, 64, {0: 0.6838852991901321, 1: 1.859543155983922}, 1.0002959091582149, 0.6, 0.8636363636363636, 0.6333333333333333, 0.7307692307692307, 0.5035793781280518, 0.7638483047485352, 0.7617474794387817, 0.5229560136795044, 0.6201065182685852, 0.557114839553833, 0.5324252843856812, 0.5176486372947693, 0.5035793781280518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6635501980781555, 0.7345799207687378, 0.7443011999130249, 0.7557365894317627, 0.7638483047485352, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8540927171707153, 0.7617474794387817, 1.054957628250122, 0.8772133588790894, 0.8657389879226685, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4504990577697754, 0.5229560136795044, 0.395073264837265, 0.46200892329216003, 0.482990026473999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_6 (Embedding)      (None, 64, 300)           36052500  \n","_________________________________________________________________\n","bidirectional_6 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","dropout_13 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 37,324,821\n","Trainable params: 1,272,321\n","Non-trainable params: 36,052,500\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.88969, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus7rnn-fixed1.h5\n","169/169 - 38s - loss: 0.6283 - acc: 0.6441 - val_loss: 0.8897 - val_acc: 0.3731\n","Epoch 2/20\n","\n","Epoch 00002: val_loss improved from 0.88969 to 0.77388, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus7rnn-fixed1.h5\n","169/169 - 37s - loss: 0.5559 - acc: 0.7332 - val_loss: 0.7739 - val_acc: 0.5066\n","Epoch 3/20\n","\n","Epoch 00003: val_loss improved from 0.77388 to 0.74774, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus7rnn-fixed1.h5\n","169/169 - 37s - loss: 0.5422 - acc: 0.7413 - val_loss: 0.7477 - val_acc: 0.5085\n","Epoch 4/20\n","\n","Epoch 00004: val_loss improved from 0.74774 to 0.71586, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus7rnn-fixed1.h5\n","169/169 - 37s - loss: 0.5266 - acc: 0.7515 - val_loss: 0.7159 - val_acc: 0.5831\n","Epoch 5/20\n","\n","Epoch 00005: val_loss did not improve from 0.71586\n","169/169 - 36s - loss: 0.5060 - acc: 0.7644 - val_loss: 0.9519 - val_acc: 0.4438\n","Epoch 6/20\n","\n","Epoch 00006: val_loss did not improve from 0.71586\n","169/169 - 36s - loss: 0.4666 - acc: 0.7898 - val_loss: 0.8452 - val_acc: 0.5091\n","Epoch 7/20\n","\n","Epoch 00007: val_loss did not improve from 0.71586\n","169/169 - 36s - loss: 0.4372 - acc: 0.8064 - val_loss: 0.8451 - val_acc: 0.5018\n","['Thesaurus', 7, 1, 120174, 150000, 0.5, 64, {0: 0.6838852991901321, 1: 1.859543155983922}, 1.0002959091582149, 0.6714285714285714, 0.8627450980392157, 0.7333333333333333, 0.7927927927927927, 0.4372338056564331, 0.8063708543777466, 0.7158623933792114, 0.583053708076477, 0.6283186674118042, 0.5558869242668152, 0.5421630144119263, 0.5265961289405823, 0.5060242414474487, 0.4666234850883484, 0.4372338056564331, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6441134810447693, 0.7332143783569336, 0.741273820400238, 0.7515063881874084, 0.7644351720809937, 0.789833664894104, 0.8063708543777466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8896933794021606, 0.7738799452781677, 0.7477408647537231, 0.7158623933792114, 0.951867938041687, 0.8452196717262268, 0.8450545072555542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37311530113220215, 0.5066468715667725, 0.5085155963897705, 0.583053708076477, 0.4438309669494629, 0.5091102123260498, 0.5018050670623779, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_6 (Embedding)      (None, 64, 300)           36052500  \n","_________________________________________________________________\n","bidirectional_6 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","dropout_13 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 37,324,821\n","Trainable params: 1,272,321\n","Non-trainable params: 36,052,500\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.82554, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus7rnn-fixed2.h5\n","169/169 - 38s - loss: 0.6126 - acc: 0.6745 - val_loss: 0.8255 - val_acc: 0.4189\n","Epoch 2/20\n","\n","Epoch 00002: val_loss did not improve from 0.82554\n","169/169 - 36s - loss: 0.5521 - acc: 0.7360 - val_loss: 1.2019 - val_acc: 0.3618\n","Epoch 3/20\n","\n","Epoch 00003: val_loss improved from 0.82554 to 0.78832, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus7rnn-fixed2.h5\n","169/169 - 37s - loss: 0.5348 - acc: 0.7457 - val_loss: 0.7883 - val_acc: 0.4968\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.78832\n","169/169 - 36s - loss: 0.5266 - acc: 0.7505 - val_loss: 0.9143 - val_acc: 0.4294\n","Epoch 5/20\n","\n","Epoch 00005: val_loss improved from 0.78832 to 0.77766, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus7rnn-fixed2.h5\n","169/169 - 37s - loss: 0.5041 - acc: 0.7629 - val_loss: 0.7777 - val_acc: 0.5429\n","Epoch 6/20\n","\n","Epoch 00006: val_loss did not improve from 0.77766\n","169/169 - 36s - loss: 0.4806 - acc: 0.7813 - val_loss: 1.0121 - val_acc: 0.4509\n","Epoch 7/20\n","\n","Epoch 00007: val_loss did not improve from 0.77766\n","169/169 - 36s - loss: 0.4447 - acc: 0.8012 - val_loss: 1.1374 - val_acc: 0.4071\n","Epoch 8/20\n","\n","Epoch 00008: val_loss improved from 0.77766 to 0.73069, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus7rnn-fixed2.h5\n","169/169 - 37s - loss: 0.4158 - acc: 0.8154 - val_loss: 0.7307 - val_acc: 0.5820\n","Epoch 9/20\n","\n","Epoch 00009: val_loss did not improve from 0.73069\n","169/169 - 36s - loss: 0.3974 - acc: 0.8230 - val_loss: 1.3109 - val_acc: 0.4040\n","Epoch 10/20\n","\n","Epoch 00010: val_loss did not improve from 0.73069\n","169/169 - 36s - loss: 0.3569 - acc: 0.8418 - val_loss: 1.6855 - val_acc: 0.3809\n","Epoch 11/20\n","\n","Epoch 00011: val_loss did not improve from 0.73069\n","169/169 - 36s - loss: 0.3220 - acc: 0.8568 - val_loss: 1.7931 - val_acc: 0.3329\n","['Thesaurus', 7, 2, 120174, 150000, 0.5, 64, {0: 0.6838852991901321, 1: 1.859543155983922}, 1.0002959091582149, 0.7428571428571429, 0.8888888888888888, 0.8, 0.8421052631578948, 0.32196471095085144, 0.8568133115768433, 0.7306889295578003, 0.5820344090461731, 0.6126416921615601, 0.5520708560943604, 0.534843385219574, 0.5265951752662659, 0.5041153430938721, 0.4805983901023865, 0.4447486698627472, 0.4157834053039551, 0.397418349981308, 0.3568909466266632, 0.32196471095085144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6745498180389404, 0.7359512448310852, 0.7456666827201843, 0.7504953742027283, 0.7629476189613342, 0.7813442349433899, 0.8011760711669922, 0.8154180645942688, 0.8229951858520508, 0.8418043255805969, 0.8568133115768433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8255366086959839, 1.2019256353378296, 0.7883212566375732, 0.9143221974372864, 0.7776620388031006, 1.0121159553527832, 1.1374356746673584, 0.7306889295578003, 1.31086266040802, 1.685538649559021, 1.7931407690048218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4188999831676483, 0.3618178069591522, 0.496835857629776, 0.4294329881668091, 0.542875349521637, 0.45088130235671997, 0.4071352779865265, 0.5820344090461731, 0.40399235486984253, 0.3809301257133484, 0.3328944444656372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Number of new embeddings:  0\n","Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_7 (Embedding)      (None, 64, 300)           36088800  \n","_________________________________________________________________\n","bidirectional_7 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_14 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","dropout_15 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 37,361,121\n","Trainable params: 1,272,321\n","Non-trainable params: 36,088,800\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.80119, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus8rnn-fixed0.h5\n","174/174 - 40s - loss: 0.6152 - acc: 0.6713 - val_loss: 0.8012 - val_acc: 0.4278\n","Epoch 2/20\n","\n","Epoch 00002: val_loss did not improve from 0.80119\n","174/174 - 37s - loss: 0.5584 - acc: 0.7316 - val_loss: 0.8884 - val_acc: 0.4116\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.80119\n","174/174 - 37s - loss: 0.5354 - acc: 0.7441 - val_loss: 0.9487 - val_acc: 0.4405\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.80119\n","174/174 - 37s - loss: 0.5085 - acc: 0.7614 - val_loss: 0.9439 - val_acc: 0.4215\n","['Thesaurus', 8, 0, 120295, 150000, 0.5, 64, {0: 0.7068699681298332, 1: 1.7084886088593494}, 0.8825176758261563, 0.34285714285714286, 0.9375, 0.25, 0.39473684210526316, 0.5084527134895325, 0.7614135146141052, 0.8011888265609741, 0.44051817059516907, 0.6151851415634155, 0.5584337115287781, 0.5354043841362, 0.5084527134895325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6712802648544312, 0.7315677404403687, 0.7441098093986511, 0.7614135146141052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8011888265609741, 0.8884329795837402, 0.9487164616584778, 0.943936288356781, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42781907320022583, 0.4116372764110565, 0.44051817059516907, 0.42149075865745544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_7 (Embedding)      (None, 64, 300)           36088800  \n","_________________________________________________________________\n","bidirectional_7 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_14 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","dropout_15 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 37,361,121\n","Trainable params: 1,272,321\n","Non-trainable params: 36,088,800\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 1.18217, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus8rnn-fixed1.h5\n","174/174 - 39s - loss: 0.6100 - acc: 0.6781 - val_loss: 1.1822 - val_acc: 0.3718\n","Epoch 2/20\n","\n","Epoch 00002: val_loss improved from 1.18217 to 0.95196, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus8rnn-fixed1.h5\n","174/174 - 38s - loss: 0.5482 - acc: 0.7362 - val_loss: 0.9520 - val_acc: 0.3721\n","Epoch 3/20\n","\n","Epoch 00003: val_loss improved from 0.95196 to 0.85057, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus8rnn-fixed1.h5\n","174/174 - 38s - loss: 0.5295 - acc: 0.7478 - val_loss: 0.8506 - val_acc: 0.4330\n","Epoch 4/20\n","\n","Epoch 00004: val_loss improved from 0.85057 to 0.81477, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus8rnn-fixed1.h5\n","174/174 - 38s - loss: 0.5024 - acc: 0.7645 - val_loss: 0.8148 - val_acc: 0.4829\n","Epoch 5/20\n","\n","Epoch 00005: val_loss did not improve from 0.81477\n","174/174 - 37s - loss: 0.4651 - acc: 0.7849 - val_loss: 1.1582 - val_acc: 0.4084\n","Epoch 6/20\n","\n","Epoch 00006: val_loss did not improve from 0.81477\n","174/174 - 37s - loss: 0.4397 - acc: 0.8016 - val_loss: 1.2430 - val_acc: 0.3924\n","Epoch 7/20\n","\n","Epoch 00007: val_loss did not improve from 0.81477\n","174/174 - 37s - loss: 0.3992 - acc: 0.8205 - val_loss: 1.6760 - val_acc: 0.3336\n","['Thesaurus', 8, 1, 120295, 150000, 0.5, 64, {0: 0.7068699681298332, 1: 1.7084886088593494}, 0.8825176758261563, 0.45714285714285713, 0.9230769230769231, 0.4, 0.5581395348837209, 0.39917460083961487, 0.8204642534255981, 0.8147671222686768, 0.48294755816459656, 0.6099812388420105, 0.5481997728347778, 0.529499351978302, 0.502359926700592, 0.46508219838142395, 0.43966609239578247, 0.39917460083961487, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6781387329101562, 0.7362281680107117, 0.7477807998657227, 0.7644661068916321, 0.7849404811859131, 0.8015527129173279, 0.8204642534255981, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1821739673614502, 0.9519577026367188, 0.8505722284317017, 0.8147671222686768, 1.158194899559021, 1.2429803609848022, 1.6760435104370117, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3717562258243561, 0.3720959722995758, 0.4330006241798401, 0.48294755816459656, 0.40836694836616516, 0.39239752292633057, 0.3336164653301239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_7 (Embedding)      (None, 64, 300)           36088800  \n","_________________________________________________________________\n","bidirectional_7 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_14 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","dropout_15 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 37,361,121\n","Trainable params: 1,272,321\n","Non-trainable params: 36,088,800\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.84434, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus8rnn-fixed2.h5\n","174/174 - 39s - loss: 0.6186 - acc: 0.6659 - val_loss: 0.8443 - val_acc: 0.4229\n","Epoch 2/20\n","\n","Epoch 00002: val_loss improved from 0.84434 to 0.82253, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus8rnn-fixed2.h5\n","174/174 - 38s - loss: 0.5542 - acc: 0.7311 - val_loss: 0.8225 - val_acc: 0.4821\n","Epoch 3/20\n","\n","Epoch 00003: val_loss improved from 0.82253 to 0.81721, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus8rnn-fixed2.h5\n","174/174 - 38s - loss: 0.5367 - acc: 0.7408 - val_loss: 0.8172 - val_acc: 0.5007\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.81721\n","174/174 - 37s - loss: 0.5215 - acc: 0.7494 - val_loss: 0.9197 - val_acc: 0.4413\n","Epoch 5/20\n","\n","Epoch 00005: val_loss did not improve from 0.81721\n","174/174 - 37s - loss: 0.4974 - acc: 0.7641 - val_loss: 0.9236 - val_acc: 0.4646\n","Epoch 6/20\n","\n","Epoch 00006: val_loss did not improve from 0.81721\n","174/174 - 37s - loss: 0.4666 - acc: 0.7836 - val_loss: 1.1032 - val_acc: 0.3958\n","['Thesaurus', 8, 2, 120295, 150000, 0.5, 64, {0: 0.7068699681298332, 1: 1.7084886088593494}, 0.8825176758261563, 0.5571428571428572, 0.967741935483871, 0.5, 0.6593406593406593, 0.46657970547676086, 0.7836025357246399, 0.8172135353088379, 0.5007432699203491, 0.6186456084251404, 0.5541577935218811, 0.5366613864898682, 0.5215147733688354, 0.49738118052482605, 0.46657970547676086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6658721566200256, 0.7311292290687561, 0.7408435940742493, 0.7493942379951477, 0.7641007304191589, 0.7836025357246399, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8443439602851868, 0.8225252032279968, 0.8172135353088379, 0.9196643233299255, 0.9236009120941162, 1.1032341718673706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42289233207702637, 0.4820981025695801, 0.5007432699203491, 0.4412826597690582, 0.4645572304725647, 0.39575281739234924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Number of new embeddings:  0\n","Model: \"sequential_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_8 (Embedding)      (None, 64, 300)           36116700  \n","_________________________________________________________________\n","bidirectional_8 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_16 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","dropout_17 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 37,389,021\n","Trainable params: 1,272,321\n","Non-trainable params: 36,116,700\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.84050, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus9rnn-fixed0.h5\n","180/180 - 41s - loss: 0.6059 - acc: 0.6736 - val_loss: 0.8405 - val_acc: 0.4164\n","Epoch 2/20\n","\n","Epoch 00002: val_loss did not improve from 0.84050\n","180/180 - 39s - loss: 0.5441 - acc: 0.7329 - val_loss: 0.8931 - val_acc: 0.4237\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.84050\n","180/180 - 38s - loss: 0.5284 - acc: 0.7450 - val_loss: 0.9175 - val_acc: 0.4319\n","Epoch 4/20\n","\n","Epoch 00004: val_loss improved from 0.84050 to 0.78792, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus9rnn-fixed0.h5\n","180/180 - 39s - loss: 0.5093 - acc: 0.7572 - val_loss: 0.7879 - val_acc: 0.5352\n","Epoch 5/20\n","\n","Epoch 00005: val_loss did not improve from 0.78792\n","180/180 - 38s - loss: 0.4848 - acc: 0.7715 - val_loss: 1.0886 - val_acc: 0.3889\n","Epoch 6/20\n","\n","Epoch 00006: val_loss did not improve from 0.78792\n","180/180 - 38s - loss: 0.4527 - acc: 0.7929 - val_loss: 1.0714 - val_acc: 0.4093\n","Epoch 7/20\n","\n","Epoch 00007: val_loss did not improve from 0.78792\n","180/180 - 38s - loss: 0.4172 - acc: 0.8118 - val_loss: 1.3851 - val_acc: 0.3419\n","['Thesaurus', 9, 0, 120388, 150000, 0.5, 64, {0: 0.7299142446134649, 1: 1.5873619441035658}, 0.7769017085313302, 0.5142857142857142, 0.9642857142857143, 0.45, 0.6136363636363636, 0.41715118288993835, 0.8118031620979309, 0.7879167795181274, 0.5351879596710205, 0.6059000492095947, 0.5441224575042725, 0.5283583998680115, 0.5093436241149902, 0.4847872853279114, 0.4527274966239929, 0.41715118288993835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.673584520816803, 0.7328996062278748, 0.7449913024902344, 0.7571700811386108, 0.771526575088501, 0.7928680181503296, 0.8118031620979309, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8404989242553711, 0.8931100368499756, 0.917525589466095, 0.7879167795181274, 1.0886306762695312, 1.0713831186294556, 1.3851021528244019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41635167598724365, 0.4236568212509155, 0.4318963587284088, 0.5351879596710205, 0.3888723850250244, 0.4093013405799866, 0.3419409692287445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Model: \"sequential_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_8 (Embedding)      (None, 64, 300)           36116700  \n","_________________________________________________________________\n","bidirectional_8 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_16 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","dropout_17 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 37,389,021\n","Trainable params: 1,272,321\n","Non-trainable params: 36,116,700\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.88972, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus9rnn-fixed1.h5\n","180/180 - 40s - loss: 0.6113 - acc: 0.6738 - val_loss: 0.8897 - val_acc: 0.3710\n","Epoch 2/20\n","\n","Epoch 00002: val_loss did not improve from 0.88972\n","180/180 - 38s - loss: 0.5513 - acc: 0.7323 - val_loss: 0.9290 - val_acc: 0.4093\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.88972\n","180/180 - 38s - loss: 0.5296 - acc: 0.7439 - val_loss: 0.9295 - val_acc: 0.4449\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.88972\n","180/180 - 38s - loss: 0.4978 - acc: 0.7654 - val_loss: 1.0703 - val_acc: 0.3662\n","['Thesaurus', 9, 1, 120388, 150000, 0.5, 64, {0: 0.7299142446134649, 1: 1.5873619441035658}, 0.7769017085313302, 0.24285714285714285, 1.0, 0.11666666666666667, 0.208955223880597, 0.4978100061416626, 0.7653636932373047, 0.8897176384925842, 0.44485029578208923, 0.6113380193710327, 0.5512771606445312, 0.52958083152771, 0.4978100061416626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6738458275794983, 0.732251763343811, 0.7438915371894836, 0.7653636932373047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8897176384925842, 0.9290032982826233, 0.9295329451560974, 1.0703041553497314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37099170684814453, 0.40934380888938904, 0.44485029578208923, 0.3662348687648773, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Model: \"sequential_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_8 (Embedding)      (None, 64, 300)           36116700  \n","_________________________________________________________________\n","bidirectional_8 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_16 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","dropout_17 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 37,389,021\n","Trainable params: 1,272,321\n","Non-trainable params: 36,116,700\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.83005, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus9rnn-fixed2.h5\n","180/180 - 41s - loss: 0.6161 - acc: 0.6571 - val_loss: 0.8301 - val_acc: 0.4235\n","Epoch 2/20\n","\n","Epoch 00002: val_loss improved from 0.83005 to 0.82239, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus9rnn-fixed2.h5\n","180/180 - 40s - loss: 0.5516 - acc: 0.7325 - val_loss: 0.8224 - val_acc: 0.4674\n","Epoch 3/20\n","\n","Epoch 00003: val_loss improved from 0.82239 to 0.80305, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus9rnn-fixed2.h5\n","180/180 - 40s - loss: 0.5342 - acc: 0.7427 - val_loss: 0.8031 - val_acc: 0.5035\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.80305\n","180/180 - 39s - loss: 0.5107 - acc: 0.7556 - val_loss: 0.8440 - val_acc: 0.5015\n","Epoch 5/20\n","\n","Epoch 00005: val_loss did not improve from 0.80305\n","180/180 - 39s - loss: 0.4785 - acc: 0.7745 - val_loss: 1.1208 - val_acc: 0.3952\n","Epoch 6/20\n","\n","Epoch 00006: val_loss did not improve from 0.80305\n","180/180 - 40s - loss: 0.4539 - acc: 0.7898 - val_loss: 0.9814 - val_acc: 0.4075\n","['Thesaurus', 9, 2, 120388, 150000, 0.5, 64, {0: 0.7299142446134649, 1: 1.5873619441035658}, 0.7769017085313302, 0.4714285714285714, 0.9259259259259259, 0.4166666666666667, 0.5747126436781609, 0.45390239357948303, 0.789770245552063, 0.8030536770820618, 0.5035039186477661, 0.6161118745803833, 0.5516147017478943, 0.5342231392860413, 0.5106757283210754, 0.4785417914390564, 0.45390239357948303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6571265459060669, 0.7325021624565125, 0.7426992654800415, 0.7556402683258057, 0.7744882106781006, 0.789770245552063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8300536274909973, 0.8223907351493835, 0.8030536770820618, 0.8439967036247253, 1.1208102703094482, 0.9813950061798096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42352941632270813, 0.46736037731170654, 0.5035039186477661, 0.5015077590942383, 0.3952006697654724, 0.4074750542640686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Number of new embeddings:  0\n","Model: \"sequential_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_9 (Embedding)      (None, 64, 300)           36117900  \n","_________________________________________________________________\n","bidirectional_9 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_18 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","dropout_19 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 37,390,221\n","Trainable params: 1,272,321\n","Non-trainable params: 36,117,900\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 0.79346, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus10rnn-fixed0.h5\n","186/186 - 45s - loss: 0.6096 - acc: 0.6689 - val_loss: 0.7935 - val_acc: 0.4391\n","Epoch 2/20\n","\n","Epoch 00002: val_loss did not improve from 0.79346\n","186/186 - 40s - loss: 0.5536 - acc: 0.7274 - val_loss: 0.9133 - val_acc: 0.3942\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.79346\n","186/186 - 40s - loss: 0.5260 - acc: 0.7453 - val_loss: 1.0727 - val_acc: 0.3337\n","Epoch 4/20\n","\n","Epoch 00004: val_loss improved from 0.79346 to 0.75308, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus10rnn-fixed0.h5\n","186/186 - 44s - loss: 0.4917 - acc: 0.7692 - val_loss: 0.7531 - val_acc: 0.5856\n","Epoch 5/20\n","\n","Epoch 00005: val_loss did not improve from 0.75308\n","186/186 - 40s - loss: 0.4657 - acc: 0.7854 - val_loss: 1.0387 - val_acc: 0.3773\n","Epoch 6/20\n","\n","Epoch 00006: val_loss did not improve from 0.75308\n","186/186 - 41s - loss: 0.4374 - acc: 0.8009 - val_loss: 1.1156 - val_acc: 0.4135\n","Epoch 7/20\n","\n","Epoch 00007: val_loss did not improve from 0.75308\n","186/186 - 41s - loss: 0.4132 - acc: 0.8120 - val_loss: 1.1384 - val_acc: 0.4798\n","['Thesaurus', 10, 0, 120392, 150000, 0.5, 64, {0: 0.7529505734245725, 1: 1.48833537562447}, 0.6814139907385157, 0.7857142857142857, 0.8688524590163934, 0.8833333333333333, 0.8760330578512396, 0.4132068157196045, 0.8120405077934265, 0.7530760765075684, 0.5855595469474792, 0.6096469163894653, 0.5536366105079651, 0.5259606838226318, 0.4916909337043762, 0.4656689465045929, 0.4373587667942047, 0.4132068157196045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6688621640205383, 0.7274181246757507, 0.7453094720840454, 0.7692490220069885, 0.7854040265083313, 0.8008834719657898, 0.8120405077934265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7934635877609253, 0.9133082032203674, 1.0726879835128784, 0.7530760765075684, 1.0387042760849, 1.115577220916748, 1.138387680053711, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4390740990638733, 0.3942238390445709, 0.3337014317512512, 0.5855595469474792, 0.37727755308151245, 0.41350606083869934, 0.47976216673851013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Model: \"sequential_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_9 (Embedding)      (None, 64, 300)           36117900  \n","_________________________________________________________________\n","bidirectional_9 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_18 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","dropout_19 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 37,390,221\n","Trainable params: 1,272,321\n","Non-trainable params: 36,117,900\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 1.04120, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus10rnn-fixed1.h5\n","186/186 - 43s - loss: 0.6233 - acc: 0.6452 - val_loss: 1.0412 - val_acc: 0.3391\n","Epoch 2/20\n","\n","Epoch 00002: val_loss improved from 1.04120 to 0.70899, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus10rnn-fixed1.h5\n","186/186 - 41s - loss: 0.5568 - acc: 0.7214 - val_loss: 0.7090 - val_acc: 0.5921\n","Epoch 3/20\n","\n","Epoch 00003: val_loss improved from 0.70899 to 0.66761, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus10rnn-fixed1.h5\n","186/186 - 47s - loss: 0.5329 - acc: 0.7369 - val_loss: 0.6676 - val_acc: 0.5839\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.66761\n","186/186 - 40s - loss: 0.5097 - acc: 0.7525 - val_loss: 0.7385 - val_acc: 0.5628\n","Epoch 5/20\n","\n","Epoch 00005: val_loss did not improve from 0.66761\n","186/186 - 40s - loss: 0.4783 - acc: 0.7734 - val_loss: 1.0157 - val_acc: 0.4394\n","Epoch 6/20\n","\n","Epoch 00006: val_loss did not improve from 0.66761\n","186/186 - 40s - loss: 0.4482 - acc: 0.7927 - val_loss: 1.0072 - val_acc: 0.4590\n","['Thesaurus', 10, 1, 120392, 150000, 0.5, 64, {0: 0.7529505734245725, 1: 1.48833537562447}, 0.6814139907385157, 0.7, 0.8679245283018868, 0.7666666666666667, 0.8141592920353983, 0.4482063949108124, 0.7926713824272156, 0.6676107048988342, 0.5921002626419067, 0.6233165264129639, 0.5568277835845947, 0.5328752994537354, 0.5096839070320129, 0.47830134630203247, 0.4482063949108124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6452181339263916, 0.721396267414093, 0.7369179129600525, 0.7524818181991577, 0.7733867168426514, 0.7926713824272156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0412003993988037, 0.7089906930923462, 0.6676107048988342, 0.7385455369949341, 1.015708327293396, 1.0072146654129028, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33905288577079773, 0.5921002626419067, 0.5839031934738159, 0.5627521872520447, 0.4394138753414154, 0.45899340510368347, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Model: \"sequential_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_9 (Embedding)      (None, 64, 300)           36117900  \n","_________________________________________________________________\n","bidirectional_9 (Bidirection (None, 512)               1140736   \n","_________________________________________________________________\n","dropout_18 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","dropout_19 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 37,390,221\n","Trainable params: 1,272,321\n","Non-trainable params: 36,117,900\n","_________________________________________________________________\n","Epoch 1/20\n","\n","Epoch 00001: val_loss improved from inf to 1.00024, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus10rnn-fixed2.h5\n","186/186 - 42s - loss: 0.6068 - acc: 0.6769 - val_loss: 1.0002 - val_acc: 0.3420\n","Epoch 2/20\n","\n","Epoch 00002: val_loss improved from 1.00024 to 0.76932, saving model to /content/drive/My Drive/Code/datadata_aumentation_for_author_profiling/weights/depresion19Thesaurus10rnn-fixed2.h5\n","186/186 - 42s - loss: 0.5508 - acc: 0.7307 - val_loss: 0.7693 - val_acc: 0.5231\n","Epoch 3/20\n","\n","Epoch 00003: val_loss did not improve from 0.76932\n","186/186 - 40s - loss: 0.5305 - acc: 0.7432 - val_loss: 1.0204 - val_acc: 0.4148\n","Epoch 4/20\n","\n","Epoch 00004: val_loss did not improve from 0.76932\n","186/186 - 40s - loss: 0.4991 - acc: 0.7644 - val_loss: 0.9623 - val_acc: 0.4189\n","Epoch 5/20\n","\n","Epoch 00005: val_loss did not improve from 0.76932\n","186/186 - 40s - loss: 0.4662 - acc: 0.7859 - val_loss: 1.5163 - val_acc: 0.3548\n","['Thesaurus', 10, 2, 120392, 150000, 0.5, 64, {0: 0.7529505734245725, 1: 1.48833537562447}, 0.6814139907385157, 0.5, 0.9629629629629629, 0.43333333333333335, 0.5977011494252873, 0.46622952818870544, 0.7858895659446716, 0.7693182826042175, 0.523125946521759, 0.6067508459091187, 0.5508174300193787, 0.5304813385009766, 0.4991209805011749, 0.46622952818870544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6769159436225891, 0.7306638956069946, 0.7432353496551514, 0.7644094228744507, 0.7858895659446716, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0002387762069702, 0.7693182826042175, 1.0203737020492554, 0.9623046517372131, 1.5162957906723022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.341983437538147, 0.523125946521759, 0.4147801995277405, 0.41885751485824585, 0.3548099398612976, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4mtlGkbXvbvj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597369304816,"user_tz":300,"elapsed":7072972,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}}},"source":[""],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"5kG-ekudbXbo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":538},"executionInfo":{"status":"ok","timestamp":1597369304817,"user_tz":300,"elapsed":7072957,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}},"outputId":"7b1b6f01-68f4-4777-f7dd-f4bdd914b60f"},"source":["for score in scores:\n","  print(score)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["['Thesaurus', 1, 0, 119135, 150000, 0.5, 64, {0: 0.5457825675750856, 1: 5.960593698463675}, 2.3907047003877886, 0.6285714285714286, 0.8863636363636364, 0.65, 0.75, 0.5523725152015686, 0.7562252283096313, 0.7109277248382568, 0.5190061330795288, 0.7390488386154175, 0.6041590571403503, 0.5756254196166992, 0.5632308721542358, 0.5523725152015686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.496934711933136, 0.731309711933136, 0.7434179782867432, 0.7562252283096313, 0.7533201575279236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7418658137321472, 0.7109277248382568, 0.7803154587745667, 1.2034186124801636, 0.8780515193939209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4701635241508484, 0.5190061330795288, 0.44531747698783875, 0.37668293714523315, 0.42348694801330566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 1, 1, 119135, 150000, 0.5, 64, {0: 0.5457825675750856, 1: 5.960593698463675}, 2.3907047003877886, 0.6428571428571429, 0.8888888888888888, 0.6666666666666666, 0.761904761904762, 0.5640854835510254, 0.7550748586654663, 0.6991814374923706, 0.5085155963897705, 0.7655813694000244, 0.6038633584976196, 0.5864703059196472, 0.5758212804794312, 0.5640854835510254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4760819673538208, 0.7316228151321411, 0.7550748586654663, 0.7505679130554199, 0.7495267391204834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8507258296012878, 0.6991814374923706, 1.0192536115646362, 1.0306447744369507, 0.8524749279022217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3812699019908905, 0.5085155963897705, 0.304905503988266, 0.3236355781555176, 0.44947972893714905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 1, 2, 119135, 150000, 0.5, 64, {0: 0.5457825675750856, 1: 5.960593698463675}, 2.3907047003877886, 0.5285714285714286, 0.9090909090909091, 0.5, 0.6451612903225806, 0.5694287419319153, 0.7408114075660706, 0.7409059405326843, 0.465151846408844, 0.7792268991470337, 0.6222994327545166, 0.5872784852981567, 0.5694287419319153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45912453532218933, 0.6903978586196899, 0.72916179895401, 0.7408114075660706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7409059405326843, 0.7500208020210266, 0.8228934407234192, 0.8190013766288757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.465151846408844, 0.44829049706459045, 0.4287959337234497, 0.43151411414146423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 2, 0, 119378, 150000, 0.5, 64, {0: 0.5687950533686209, 1: 4.1339822088724585}, 1.983476254779634, 0.5571428571428572, 0.9142857142857143, 0.5333333333333333, 0.6736842105263158, 0.5303364992141724, 0.7598351240158081, 0.7339245080947876, 0.5380760431289673, 0.7549962401390076, 0.5962072610855103, 0.5785683393478394, 0.5603291392326355, 0.5490819215774536, 0.5370880961418152, 0.5303364992141724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4737066328525543, 0.742194414138794, 0.7598351240158081, 0.7509344220161438, 0.7467285990715027, 0.754665195941925, 0.7588081359863281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8514019250869751, 0.8135461807250977, 0.8790398240089417, 0.7339245080947876, 0.9765340685844421, 0.8160926699638367, 0.9275255799293518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35238903760910034, 0.396389901638031, 0.3264387249946594, 0.5380760431289673, 0.42493098974227905, 0.46638351678848267, 0.38012316823005676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 2, 1, 119378, 150000, 0.5, 64, {0: 0.5687950533686209, 1: 4.1339822088724585}, 1.983476254779634, 0.5857142857142857, 0.8974358974358975, 0.5833333333333334, 0.7070707070707071, 0.5652428865432739, 0.7669682502746582, 0.746063232421875, 0.4694415032863617, 0.7554509043693542, 0.5958590507507324, 0.5775996446609497, 0.5652428865432739, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4790722131729126, 0.7442344427108765, 0.7669682502746582, 0.7540364265441895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.746063232421875, 0.8503357768058777, 0.9206110239028931, 0.8475024700164795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4694415032863617, 0.3606710433959961, 0.35931196808815, 0.4126990735530853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 2, 2, 119378, 150000, 0.5, 64, {0: 0.5687950533686209, 1: 4.1339822088724585}, 1.983476254779634, 0.5285714285714286, 0.8648648648648649, 0.5333333333333333, 0.6597938144329898, 0.532768189907074, 0.7522897720336914, 0.7325745224952698, 0.5079634785652161, 0.7173711061477661, 0.6028207540512085, 0.5768615007400513, 0.562320351600647, 0.5456681251525879, 0.532768189907074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.508994996547699, 0.7194886207580566, 0.7268243432044983, 0.7361721396446228, 0.744458019733429, 0.7522897720336914, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7917695045471191, 0.774373471736908, 0.7325745224952698, 0.9041884541511536, 0.9394355416297913, 0.9138451814651489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39239752292633057, 0.45092377066612244, 0.5079634785652161, 0.3523465692996979, 0.421448290348053, 0.42115098237991333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 3, 0, 119610, 150000, 0.5, 64, {0: 0.5918115129984184, 1: 3.2229700484764545}, 1.6948703947332893, 0.5142857142857142, 0.8823529411764706, 0.5, 0.6382978723404256, 0.5500746369361877, 0.7501124739646912, 0.7231831550598145, 0.468719482421875, 0.7148877382278442, 0.5902256369590759, 0.5662277340888977, 0.5500746369361877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5198318362236023, 0.7494410276412964, 0.7501124739646912, 0.7496894598007202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7231831550598145, 0.7942537069320679, 0.9026620984077454, 0.9271824955940247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.468719482421875, 0.4002973139286041, 0.3924824893474579, 0.46451476216316223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 3, 1, 119610, 150000, 0.5, 64, {0: 0.5918115129984184, 1: 3.2229700484764545}, 1.6948703947332893, 0.4857142857142857, 0.9, 0.45, 0.6, 0.545594334602356, 0.7473796010017395, 0.7909324169158936, 0.4421320855617523, 0.65833580493927, 0.5857086777687073, 0.5590552687644958, 0.545594334602356, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6001463532447815, 0.731774628162384, 0.7466946840286255, 0.7473796010017395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7909324169158936, 0.9422025680541992, 0.8735074400901794, 0.8662606477737427, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4114249348640442, 0.3573157787322998, 0.4421320855617523, 0.43113186955451965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 3, 2, 119610, 150000, 0.5, 64, {0: 0.5918115129984184, 1: 3.2229700484764545}, 1.6948703947332893, 0.4, 0.95, 0.31666666666666665, 0.4749999999999999, 0.5515599250793457, 0.7415915131568909, 0.7559108138084412, 0.48201316595077515, 0.7302101850509644, 0.5920588374137878, 0.5674872994422913, 0.5515599250793457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5037165880203247, 0.7347425222396851, 0.7338628768920898, 0.7415915131568909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7559108138084412, 0.8449685573577881, 0.7688276171684265, 0.789486289024353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.426757276058197, 0.40658313035964966, 0.4516882598400116, 0.48201316595077515, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 4, 0, 119741, 150000, 0.5, 64, {0: 0.6148359203007399, 1: 2.6770191708768776}, 1.4711037688722857, 0.34285714285714286, 0.9375, 0.25, 0.39473684210526316, 0.5201846361160278, 0.7676333785057068, 0.8401395678520203, 0.4840942919254303, 0.6965358853340149, 0.5747877955436707, 0.550711452960968, 0.535679817199707, 0.5201846361160278, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5477020144462585, 0.7478945851325989, 0.7434478998184204, 0.7528519034385681, 0.7676333785057068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8964100480079651, 0.8401395678520203, 0.8693966865539551, 0.9410485029220581, 0.8882347941398621, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35166701674461365, 0.42276492714881897, 0.42722445726394653, 0.40896156430244446, 0.4840942919254303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 4, 1, 119741, 150000, 0.5, 64, {0: 0.6148359203007399, 1: 2.6770191708768776}, 1.4711037688722857, 0.5714285714285714, 0.8947368421052632, 0.5666666666666667, 0.6938775510204083, 0.5477373600006104, 0.7501567602157593, 0.7286137342453003, 0.4724145233631134, 0.6579127311706543, 0.5812795162200928, 0.5575545430183411, 0.5477373600006104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6066726446151733, 0.7285242676734924, 0.7444367408752441, 0.7501567602157593, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7286137342453003, 0.8254004716873169, 0.8039093017578125, 0.9553460478782654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4724145233631134, 0.43079209327697754, 0.46816733479499817, 0.3901040554046631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 4, 2, 119741, 150000, 0.5, 64, {0: 0.6148359203007399, 1: 2.6770191708768776}, 1.4711037688722857, 0.7142857142857143, 0.8448275862068966, 0.8166666666666667, 0.8305084745762712, 0.5461557507514954, 0.7470996379852295, 0.6906864047050476, 0.5549373626708984, 0.6719282865524292, 0.578691840171814, 0.5575836300849915, 0.5461557507514954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5693409442901611, 0.7208782434463501, 0.7431376576423645, 0.7470996379852295, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6906864047050476, 1.0986742973327637, 0.731951117515564, 1.1519688367843628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5549373626708984, 0.32223403453826904, 0.5272881984710693, 0.3773624897003174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 5, 0, 119923, 150000, 0.5, 64, {0: 0.6378762229481096, 1: 2.313220544154946}, 1.2882517509106401, 0.6285714285714286, 0.8541666666666666, 0.6833333333333333, 0.7592592592592592, 0.5313342213630676, 0.7531507015228271, 0.7047932744026184, 0.5198131203651428, 0.6384124755859375, 0.5739018321037292, 0.5511488914489746, 0.5313342213630676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6328160762786865, 0.7201889157295227, 0.7379749417304993, 0.7531507015228271, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7047932744026184, 0.7665608525276184, 0.8051616549491882, 0.8598889708518982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5198131203651428, 0.4493098258972168, 0.48035675287246704, 0.42030155658721924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 5, 1, 119923, 150000, 0.5, 64, {0: 0.6378762229481096, 1: 2.313220544154946}, 1.2882517509106401, 0.6857142857142857, 0.8518518518518519, 0.7666666666666667, 0.8070175438596491, 0.5250306129455566, 0.7612868547439575, 0.7004138231277466, 0.554385244846344, 0.6217848062515259, 0.5666900873184204, 0.5454013347625732, 0.5250306129455566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6605635285377502, 0.7329599857330322, 0.746671736240387, 0.7612868547439575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7004138231277466, 0.8353338241577148, 0.9121208190917969, 0.9367709159851074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.554385244846344, 0.4281163811683655, 0.4414525330066681, 0.4453599452972412, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 5, 2, 119923, 150000, 0.5, 64, {0: 0.6378762229481096, 1: 2.313220544154946}, 1.2882517509106401, 0.34285714285714286, 0.8888888888888888, 0.26666666666666666, 0.41025641025641024, 0.45459139347076416, 0.8013194799423218, 0.8574418425559998, 0.4701210558414459, 0.6498685479164124, 0.5729726552963257, 0.5466099381446838, 0.5349365472793579, 0.5188189744949341, 0.49704620242118835, 0.47053995728492737, 0.45459139347076416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6120147705078125, 0.736211895942688, 0.7491137981414795, 0.7533376216888428, 0.7646883130073547, 0.7776151299476624, 0.7921554446220398, 0.8013194799423218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9112229943275452, 0.8675852417945862, 0.9010098576545715, 0.8807067275047302, 0.8574418425559998, 0.884204089641571, 1.1861263513565063, 0.9880574345588684, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3307283818721771, 0.42017412185668945, 0.4342747926712036, 0.4701210558414459, 0.44174984097480774, 0.4514334201812744, 0.3963049352169037, 0.4655340909957886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 6, 0, 120008, 150000, 0.5, 64, {0: 0.6608608918878106, 1: 2.0541378458498025}, 1.134068132464495, 0.45714285714285713, 0.9583333333333334, 0.38333333333333336, 0.5476190476190476, 0.521682858467102, 0.7575148940086365, 0.7939248085021973, 0.4872796833515167, 0.6276333928108215, 0.5668756365776062, 0.5422806143760681, 0.521682858467102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6459174156188965, 0.7274793386459351, 0.7467874884605408, 0.7575148940086365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7939248085021973, 1.0066081285476685, 0.8030921220779419, 0.9631925821304321, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42293480038642883, 0.3763006925582886, 0.4872796833515167, 0.43839457631111145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 6, 1, 120008, 150000, 0.5, 64, {0: 0.6608608918878106, 1: 2.0541378458498025}, 1.134068132464495, 0.22857142857142856, 1.0, 0.1, 0.18181818181818182, 0.48653310537338257, 0.7747605443000793, 0.8984289765357971, 0.4574219584465027, 0.6257790923118591, 0.5650733709335327, 0.5471505522727966, 0.5302534103393555, 0.50767982006073, 0.48653310537338257, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6567109227180481, 0.7288624048233032, 0.7388200759887695, 0.750112771987915, 0.7630228996276855, 0.7747605443000793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9130292534828186, 0.9258144497871399, 0.8984289765357971, 1.0218281745910645, 0.9087539911270142, 0.9969661831855774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3589721918106079, 0.37082183361053467, 0.41363346576690674, 0.3881928324699402, 0.4574219584465027, 0.4463368058204651, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 6, 2, 120008, 150000, 0.5, 64, {0: 0.6608608918878106, 1: 2.0541378458498025}, 1.134068132464495, 0.6, 0.9, 0.6, 0.7200000000000001, 0.5295224785804749, 0.7499383687973022, 0.7537975907325745, 0.47797834873199463, 0.6562120914459229, 0.5708787441253662, 0.5466402769088745, 0.5295224785804749, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6036511659622192, 0.7330474853515625, 0.7390906810760498, 0.7499383687973022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7537975907325745, 0.8537267446517944, 0.8890822529792786, 0.8717172145843506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47797834873199463, 0.3906986713409424, 0.44710129499435425, 0.4483329653739929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 7, 0, 120174, 150000, 0.5, 64, {0: 0.6838852991901321, 1: 1.859543155983922}, 1.0002959091582149, 0.6, 0.8636363636363636, 0.6333333333333333, 0.7307692307692307, 0.5035793781280518, 0.7638483047485352, 0.7617474794387817, 0.5229560136795044, 0.6201065182685852, 0.557114839553833, 0.5324252843856812, 0.5176486372947693, 0.5035793781280518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6635501980781555, 0.7345799207687378, 0.7443011999130249, 0.7557365894317627, 0.7638483047485352, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8540927171707153, 0.7617474794387817, 1.054957628250122, 0.8772133588790894, 0.8657389879226685, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4504990577697754, 0.5229560136795044, 0.395073264837265, 0.46200892329216003, 0.482990026473999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 7, 1, 120174, 150000, 0.5, 64, {0: 0.6838852991901321, 1: 1.859543155983922}, 1.0002959091582149, 0.6714285714285714, 0.8627450980392157, 0.7333333333333333, 0.7927927927927927, 0.4372338056564331, 0.8063708543777466, 0.7158623933792114, 0.583053708076477, 0.6283186674118042, 0.5558869242668152, 0.5421630144119263, 0.5265961289405823, 0.5060242414474487, 0.4666234850883484, 0.4372338056564331, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6441134810447693, 0.7332143783569336, 0.741273820400238, 0.7515063881874084, 0.7644351720809937, 0.789833664894104, 0.8063708543777466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8896933794021606, 0.7738799452781677, 0.7477408647537231, 0.7158623933792114, 0.951867938041687, 0.8452196717262268, 0.8450545072555542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37311530113220215, 0.5066468715667725, 0.5085155963897705, 0.583053708076477, 0.4438309669494629, 0.5091102123260498, 0.5018050670623779, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 7, 2, 120174, 150000, 0.5, 64, {0: 0.6838852991901321, 1: 1.859543155983922}, 1.0002959091582149, 0.7428571428571429, 0.8888888888888888, 0.8, 0.8421052631578948, 0.32196471095085144, 0.8568133115768433, 0.7306889295578003, 0.5820344090461731, 0.6126416921615601, 0.5520708560943604, 0.534843385219574, 0.5265951752662659, 0.5041153430938721, 0.4805983901023865, 0.4447486698627472, 0.4157834053039551, 0.397418349981308, 0.3568909466266632, 0.32196471095085144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6745498180389404, 0.7359512448310852, 0.7456666827201843, 0.7504953742027283, 0.7629476189613342, 0.7813442349433899, 0.8011760711669922, 0.8154180645942688, 0.8229951858520508, 0.8418043255805969, 0.8568133115768433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8255366086959839, 1.2019256353378296, 0.7883212566375732, 0.9143221974372864, 0.7776620388031006, 1.0121159553527832, 1.1374356746673584, 0.7306889295578003, 1.31086266040802, 1.685538649559021, 1.7931407690048218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4188999831676483, 0.3618178069591522, 0.496835857629776, 0.4294329881668091, 0.542875349521637, 0.45088130235671997, 0.4071352779865265, 0.5820344090461731, 0.40399235486984253, 0.3809301257133484, 0.3328944444656372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 8, 0, 120295, 150000, 0.5, 64, {0: 0.7068699681298332, 1: 1.7084886088593494}, 0.8825176758261563, 0.34285714285714286, 0.9375, 0.25, 0.39473684210526316, 0.5084527134895325, 0.7614135146141052, 0.8011888265609741, 0.44051817059516907, 0.6151851415634155, 0.5584337115287781, 0.5354043841362, 0.5084527134895325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6712802648544312, 0.7315677404403687, 0.7441098093986511, 0.7614135146141052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8011888265609741, 0.8884329795837402, 0.9487164616584778, 0.943936288356781, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42781907320022583, 0.4116372764110565, 0.44051817059516907, 0.42149075865745544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 8, 1, 120295, 150000, 0.5, 64, {0: 0.7068699681298332, 1: 1.7084886088593494}, 0.8825176758261563, 0.45714285714285713, 0.9230769230769231, 0.4, 0.5581395348837209, 0.39917460083961487, 0.8204642534255981, 0.8147671222686768, 0.48294755816459656, 0.6099812388420105, 0.5481997728347778, 0.529499351978302, 0.502359926700592, 0.46508219838142395, 0.43966609239578247, 0.39917460083961487, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6781387329101562, 0.7362281680107117, 0.7477807998657227, 0.7644661068916321, 0.7849404811859131, 0.8015527129173279, 0.8204642534255981, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1821739673614502, 0.9519577026367188, 0.8505722284317017, 0.8147671222686768, 1.158194899559021, 1.2429803609848022, 1.6760435104370117, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3717562258243561, 0.3720959722995758, 0.4330006241798401, 0.48294755816459656, 0.40836694836616516, 0.39239752292633057, 0.3336164653301239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 8, 2, 120295, 150000, 0.5, 64, {0: 0.7068699681298332, 1: 1.7084886088593494}, 0.8825176758261563, 0.5571428571428572, 0.967741935483871, 0.5, 0.6593406593406593, 0.46657970547676086, 0.7836025357246399, 0.8172135353088379, 0.5007432699203491, 0.6186456084251404, 0.5541577935218811, 0.5366613864898682, 0.5215147733688354, 0.49738118052482605, 0.46657970547676086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6658721566200256, 0.7311292290687561, 0.7408435940742493, 0.7493942379951477, 0.7641007304191589, 0.7836025357246399, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8443439602851868, 0.8225252032279968, 0.8172135353088379, 0.9196643233299255, 0.9236009120941162, 1.1032341718673706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42289233207702637, 0.4820981025695801, 0.5007432699203491, 0.4412826597690582, 0.4645572304725647, 0.39575281739234924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 9, 0, 120388, 150000, 0.5, 64, {0: 0.7299142446134649, 1: 1.5873619441035658}, 0.7769017085313302, 0.5142857142857142, 0.9642857142857143, 0.45, 0.6136363636363636, 0.41715118288993835, 0.8118031620979309, 0.7879167795181274, 0.5351879596710205, 0.6059000492095947, 0.5441224575042725, 0.5283583998680115, 0.5093436241149902, 0.4847872853279114, 0.4527274966239929, 0.41715118288993835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.673584520816803, 0.7328996062278748, 0.7449913024902344, 0.7571700811386108, 0.771526575088501, 0.7928680181503296, 0.8118031620979309, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8404989242553711, 0.8931100368499756, 0.917525589466095, 0.7879167795181274, 1.0886306762695312, 1.0713831186294556, 1.3851021528244019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41635167598724365, 0.4236568212509155, 0.4318963587284088, 0.5351879596710205, 0.3888723850250244, 0.4093013405799866, 0.3419409692287445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 9, 1, 120388, 150000, 0.5, 64, {0: 0.7299142446134649, 1: 1.5873619441035658}, 0.7769017085313302, 0.24285714285714285, 1.0, 0.11666666666666667, 0.208955223880597, 0.4978100061416626, 0.7653636932373047, 0.8897176384925842, 0.44485029578208923, 0.6113380193710327, 0.5512771606445312, 0.52958083152771, 0.4978100061416626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6738458275794983, 0.732251763343811, 0.7438915371894836, 0.7653636932373047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8897176384925842, 0.9290032982826233, 0.9295329451560974, 1.0703041553497314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37099170684814453, 0.40934380888938904, 0.44485029578208923, 0.3662348687648773, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 9, 2, 120388, 150000, 0.5, 64, {0: 0.7299142446134649, 1: 1.5873619441035658}, 0.7769017085313302, 0.4714285714285714, 0.9259259259259259, 0.4166666666666667, 0.5747126436781609, 0.45390239357948303, 0.789770245552063, 0.8030536770820618, 0.5035039186477661, 0.6161118745803833, 0.5516147017478943, 0.5342231392860413, 0.5106757283210754, 0.4785417914390564, 0.45390239357948303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6571265459060669, 0.7325021624565125, 0.7426992654800415, 0.7556402683258057, 0.7744882106781006, 0.789770245552063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8300536274909973, 0.8223907351493835, 0.8030536770820618, 0.8439967036247253, 1.1208102703094482, 0.9813950061798096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42352941632270813, 0.46736037731170654, 0.5035039186477661, 0.5015077590942383, 0.3952006697654724, 0.4074750542640686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 10, 0, 120392, 150000, 0.5, 64, {0: 0.7529505734245725, 1: 1.48833537562447}, 0.6814139907385157, 0.7857142857142857, 0.8688524590163934, 0.8833333333333333, 0.8760330578512396, 0.4132068157196045, 0.8120405077934265, 0.7530760765075684, 0.5855595469474792, 0.6096469163894653, 0.5536366105079651, 0.5259606838226318, 0.4916909337043762, 0.4656689465045929, 0.4373587667942047, 0.4132068157196045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6688621640205383, 0.7274181246757507, 0.7453094720840454, 0.7692490220069885, 0.7854040265083313, 0.8008834719657898, 0.8120405077934265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7934635877609253, 0.9133082032203674, 1.0726879835128784, 0.7530760765075684, 1.0387042760849, 1.115577220916748, 1.138387680053711, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4390740990638733, 0.3942238390445709, 0.3337014317512512, 0.5855595469474792, 0.37727755308151245, 0.41350606083869934, 0.47976216673851013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 10, 1, 120392, 150000, 0.5, 64, {0: 0.7529505734245725, 1: 1.48833537562447}, 0.6814139907385157, 0.7, 0.8679245283018868, 0.7666666666666667, 0.8141592920353983, 0.4482063949108124, 0.7926713824272156, 0.6676107048988342, 0.5921002626419067, 0.6233165264129639, 0.5568277835845947, 0.5328752994537354, 0.5096839070320129, 0.47830134630203247, 0.4482063949108124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6452181339263916, 0.721396267414093, 0.7369179129600525, 0.7524818181991577, 0.7733867168426514, 0.7926713824272156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0412003993988037, 0.7089906930923462, 0.6676107048988342, 0.7385455369949341, 1.015708327293396, 1.0072146654129028, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33905288577079773, 0.5921002626419067, 0.5839031934738159, 0.5627521872520447, 0.4394138753414154, 0.45899340510368347, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","['Thesaurus', 10, 2, 120392, 150000, 0.5, 64, {0: 0.7529505734245725, 1: 1.48833537562447}, 0.6814139907385157, 0.5, 0.9629629629629629, 0.43333333333333335, 0.5977011494252873, 0.46622952818870544, 0.7858895659446716, 0.7693182826042175, 0.523125946521759, 0.6067508459091187, 0.5508174300193787, 0.5304813385009766, 0.4991209805011749, 0.46622952818870544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6769159436225891, 0.7306638956069946, 0.7432353496551514, 0.7644094228744507, 0.7858895659446716, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0002387762069702, 0.7693182826042175, 1.0203737020492554, 0.9623046517372131, 1.5162957906723022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.341983437538147, 0.523125946521759, 0.4147801995277405, 0.41885751485824585, 0.3548099398612976, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yDRn8t9R_a-X","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597369304817,"user_tz":300,"elapsed":7072937,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}}},"source":[""],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"lSUxdPescPYE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":178},"executionInfo":{"status":"error","timestamp":1597369307714,"user_tz":300,"elapsed":7075801,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}},"outputId":"7cceaf79-7bab-4725-90a7-805f74da301a"},"source":["bi_gru.save_predictions(\"/content/drive/My Drive/Code/data_aumentation_for_author_profiling/predictions/\", \"predictions_\"+model+\"_\"+augmentation_method)    \n","logger.info(\"Finish Time: %s\", datetime.now())"],"execution_count":21,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-507f8fded256>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbi_gru\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Code/data_aumentation_for_author_profiling/predictions/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predictions_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0maugmentation_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finish Time: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'logger' is not defined"]}]},{"cell_type":"code","metadata":{"id":"ETwdEoqEs1kH","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597369306975,"user_tz":300,"elapsed":7075043,"user":{"displayName":"Víctor Jiménez Villar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGf6idc6Zl61Z_kJsNGzq1M9oX-I52mC-soZ1d=s64","userId":"00192359867040618323"}}},"source":[""],"execution_count":null,"outputs":[]}]}