
\section{Aumento de datos}

El aprendizaje profundo típicamente requiere grandes cantidades de datos etiquetados para tener éxito. El aumento de datos promete resolver el problema, de la necesidad de más datos etiquetados, básicamente consiste en aplicar una serie de transformaciones a un ejemplo original para obtener un nuevo dato a partir de éste.

El término \textbf{aumento de datos}, se refiere a métodos para construir una optimización iterativa o algoritmos de muestreo mediante la introducción de datos no observados o variables latentes \citep{van2001art}. La idea del aumento de datos nació en problemas de \textbf{datos incompletos}, como una forma de completar las celdas faltantes en una tabla de contingencia balanceada \citep{dempster1977maximum}. El aumento de datos automático es mayoritariamente utilizado en tareas relacionadas a visión computacional y ayudan a realizar un entrenamiento más robusto, particularmente, cuando el tamaño de los datos es pequeño. 


Derivado del estudio del estado del arte en aumento de datos, las técnicas de aumento de datos se pueden clasificar en dos categorías (no restringidas a un solo dominio): aquellas que se basan en aprendizaje supervisado y las que utilizan un enfoque semi-supervisado. Las basadas en un enfoque supervisado crean nuevos ejemplos a partir de datos previamente etiquetados. Las que utilizan un enfoque semi-supervisado obtienen ejemplos totalmente nuevos de un modelo supervisado, supervisado débil o heurísticas conociendo la naturaleza de los datos.


\subsection{Aumento de datos supervisado} El objetivo es crear un nuevo y realista conjunto de entrenamiento, aplicando una transformación a la entrada de un ejemplo y conservando la etiqueta original del ejemplo. Formalmente, sea $q(\hat{x}|x)$ la transformación de aumento de la cual podemos extraer ejemplos aumentados $\hat{x}$ basado en un ejemplo original $x$. Para que una transformación de aumento sea válida, es requerido que cualquier ejemplo $\hat{x} \sim q(\hat{x}|x)$ extraído de la distribución, comparta la misma etiqueta de verdad que $x$, es decir $y(\hat{x})=y(x)$, \citep{xie2019unsupervised}.

El aumento de datos supervisado puede ser equivalentemente visto, como construir un conjunto aumentado etiquetado del conjunto original y entrenar el modelo en el conjunto aumentado. El punto crítico es como diseñar esa transformación, en la literatura podemos encontrar dos grupos de algoritmos para \textbf{crear} ejemplos de entrenamiento adicionales: los que operan \textbf{a nivel estructural}, los cuales crean transformaciones en un ejemplo (imagen, cadena de caracteres, texto, etc.) \citep{zhong2017random}, y \textbf{sobre muestreo sintético} creando ejemplos adicionales a nivel características, es decir, en un espacio vectorial\citep{chawla2002smote}. 

\subsection{Aumento de datos semi-supervisado}

Estos métodos tienen como característica general el aprender un modelo inicial, para posteriormente etiquetar datos nuevos obtenidos de algún dominio similar y reentrenar el modelo con estos datos nuevos. Tomando la definición de \citep{xie2019unsupervised}, la forma general de estos trabajos puede ser resumida como sigue:

\begin{itemize}
    \item Dada una entrada $x$, se calcula la distribución $p_\theta (y|x)$ dado $x$ y una versión con ruido $p_\theta (y|x, \epsilon)$ mediante la introducción de un pequeño ruido $\epsilon$. El ruido puede ser aplicado a $x$ o estados ocultos.
    \item Minimizar una métrica de divergencia entre las dos distribuciones $D (p_\theta (y|x) || p_\theta (y|x, \epsilon))$.
\end{itemize}

Este procedimiento forza el modelo a ser insensible al ruido $\epsilon$ y suave con respecto a los cambios en el espacio de entrada. Desde otra perspectiva, minimizando la pérdida de consistencia gradualmente se propaga la información de la etiqueta de ejemplos etiquetados a ejemplos no etiquetados \citep{Miyato2019}.


\subsection{Aumento de datos en clasificación de textos}

El aumento de datos ha sido ampliamente utilizado en tareas de visión computacional \citep{cubuk2019autoaugment}, pero menos en tareas de procesamiento de lenguaje natural. En años recientes ha crecido el interés por proponer diversas técnicas para el aumento de datos en la clasificación de textos, a continuación, se mencionan algunos de los métodos más relevantes para este trabajo.

\subsubsection{Basados en métodos semi-supervisados}

Datos con ruido \citep{hedderich2018training}, propusieron una capa de ruido que es agregada a una arquitectura de red neuronal, esto permite modelar el ruido y entrenar una combinación de datos limpios y con ruido. Para simular escenarios de pocos recursos, el entrenamiento fue realizado con diferentes tamaños de datos limpios, variando desde un 1\% el conjunto original hasta un 10\% (equivalentes de 407 ejemplos y 20,362 respectivamente). Comprobando que en un contexto de bajos recursos, en la tarea de reconocimiento de entidades nombradas (NER), la clasificación puede mejorar en términos de \textit{F1} en promedio hasta 10 puntos. Pero variando el tamaño del conjunto original a un 10\% la ganancia obtenida no se observa, llegando a concluir que un 10\% de datos limpios puede ser suficiente para entrenar el modelo y el ruido adicional puede perjudicar al modelo.

Reinforced Co-Training: \citep{wu2018reinforced}, este método utiliza el algoritmo Q-learning para aprender una política de selección de datos y entonces explotar esta política para co-entrenar clasificadores automáticamente. Realizaron experimentos en la detección de \textit{Clickbait}; este término se refiere a aquellos encabezados con el objetivo de atraer la atención del lector, pero los documentos usualmente tienen menos relevancia con los encabezados correspondientes. El etiquetado de este tipo de datos consume mucho tiempo y labor. En esta tarea lograron mejorar 3 puntos en términos de la métrica \textit{F1} en comparación con el modelo base entrenado en forma supervisada.

Supervisado débil \citep{han2019neural}, propusieron una técnica de aumento de datos la cual consiste en incorporar ejemplos nuevos al conjunto de entrenamiento, mediante un etiquetado basado en la búsqueda de similitudes relacionales en millones de tweets no etiquetados. Realizaron experimentos para la detección de rumores en redes sociales, logrando incrementar en promedio la métrica \textit{F1} entre 9 y 12 puntos en comparación a no realizar aumento de datos.

UDA \citep{xie2019unsupervised}, es una propuesta híbrida la cual consiste en utilizar métodos existentes de aumento de datos, reemplazo de sinónimos y traducción inversa, para aumentar datos etiquetados y no etiquetados. Mediante el entrenamiento fino del modelo no supervisado BERT, lograron aproximar el error de clasificación en 4 conjuntos de datos para la clasificación de opiniones, con un margen de un punto porcentual en comparación con el modelo entrenado en el conjunto completo de datos etiquetados. Con esto se logró comprobar que aún existe una brecha por rebasar cuando se comparan los métodos supervisados con los semi-supervisados.

Por lo general los esquemas para realizar aumento de datos de forma semi-supervisada han requerido de modelos complejos para poder implementarse. Si bien los resultados son prometedores y comparables al estado del arte, no han logrado superar el estado del arte basado en modelos supervisados.

\subsubsection{Basados en aprendizaje supervisado}

Reemplazo de sinónimos mediante un tesauro \citep{zhang2015character}: presentaron una exploración empírica de redes convolucionales a nivel carácter. Construyeron conjuntos de datos aumentados para la clasificación de opiniones, mediante el reemplazo de palabras por sus sinónimos utilizando un tesauro. Llegando a reducir el error de clasificación en 1\% menos en comparación con el estado del arte, agregando aumento de datos en cuatro de ocho conjuntos de datos.

Aumento de datos contextual \citep{kobayashi2018contextual}: asumen que el sentido de las oraciones no cambia incluso si las palabras en las oraciones son reemplazadas por otras palabras con relaciones paradigmáticas. Este método, estocásticamente reemplaza palabras con otras palabras que son predichas por un modelo de lenguaje bidireccional. Además, proponen un modelo de lenguaje condicionado a la etiqueta que permite al modelo aumentar oraciones considerando la información de la etiqueta. Mediante experimentos en 6 conjuntos de datos en clasificación temática de textos, logran mejorar la exactitud en 1\% en comparación a no realizar aumento de datos y menor a 1\% en comparación con el remplazo de sinónimos.

EDA \citep{wei2019eda}: se presenta como una alternativa simple y escalable en comparación con métodos de aumentos de datos basados en redes neuronales, EDA consiste de una combinación de cuatro operaciones a nivel palabra: reemplazo de sinónimos, inserción aleatoria, intercambio aleatorio y eliminación aleatoria. En cinco tareas de clasificación, muestran que es posible mejorar  el rendimiento en redes convolucionales y recurrentes, alcanzado entre un 1 y 2\% en comparación de modelos sin aumento de datos.

Paráfrasis neuronal \citep{kumar2019submodular}: este trabajo propone un método para obtener paráfrasis neuronales mediante el modelo seq2seq, a diferencia de otros modelos para generar paráfrasis este método busca un balance entre la diversidad y la fidelidad de las oraciones generadas; para esto proponen optimizar una función que combine estos dos factores. Los autores evaluaron su propuesta para la clasificación de intención utilizando una red LSTM y regresión logística, obteniendo una mejora de 3\% en exactitud sobre el método base que es no realizar aumento de datos y 2\% sobre reemplazo de sinónimos.

Traducción de temas \citep{zhang2019integrating}: este método traduce todas las palabras reemplazables de una oración a otras clases objetivo. Esta búsqueda de relaciones de similitud se realiza utilizando aritmética de vectores. Realizaron diversos experimentos para la clasificación de documentos mediante \textit{zero-shoot text clasification}, esta técnica de clasificación consiste en ser capaz de predecir categorías no vistas en la fase de entrenamiento. Mediante un esquema controlado de poco recursos logran obtener ganancias de 1 a 8\% en términos de exactitud, en comparación a no realizar aumento de datos.


\subsection{Discusión del trabajo relacionado}

Al revisar la literatura de los métodos de aumento de datos basados en un enfoque supervisado, podemos observar que son un tanto complejos y en muchos casos, bajo un esquema de experimentación controlando la cantidad de datos etiquetados disponibles, no logran superar a los modelos supervisados.

Todos los trabajos hasta ahora encontrados en la literatura de aumento de datos mediante un enfoque supervisado, están enfocados a la clasificación de textos cortos o clasificación temática, pero ni una enfocada a tareas de perfilado de autor o demostrado ser efectivos en conjuntos desbalanceados. En algunos casos como \textit{EDA} el reemplazo es totalmente aleatorio o la estructura del documento se corrompe al incorporar operaciones de eliminación sobre las palabras, en otros como el reemplazo de sinónimos no siempre se asegura que la palabra a reemplazar pertenezca a la misma categoría que la palabra original. Los trabajos que respetan la estructura y diversidad de la oración original están basados en modelos de redes neuronales, pero es difícil hacerlos escalables. En la tabla \ref{table:sup_meth} se presentan las principales características de los diferentes enfoques supervisados relevantes para este trabajo en comparación con el método propuesto. La propuesta de \cite{kumar2019submodular} puede considerarse que se respeta el estilo contenido de los textos, mediante la realización de una paráfrasis neuronal, pero este enfoque tiene la desventaja de utilizar un conjunto de datos externos para aprender a realizar la paráfrasis y considerando que se cuente con este recurso, el tiempo tomado para realizar una paráfrasis neuronal o predecir palabras mediante un modelo de lenguaje hace que el método no sea escalable.

En el caso de perfilado de autor, es necesario que los nuevos ejemplos aumentados respeten tanto el estilo (i.e., la estructura original) como el contenido del texto, por lo que en este trabajo se proponen métodos de aumento de datos que consideren el estilo y contenido del documento original; considerando estilo como la forma o modo de expresar el contenido, siendo el contenido el tema o mensaje a transmitir.

Los resultados hasta ahora alcanzados muestran un beneficio del uso del aumento de datos, no obstante, estos beneficios son aún modestos. Por otro lado, las técnicas simples de aumento de datos a nivel palabra han demostrado ser efectivas y escalables, y obtienen resultados comparables a técnicas complejas como la paráfrasis neuronal o modelos de lenguaje.

\input{sections/tables/metodos_supervisados}
